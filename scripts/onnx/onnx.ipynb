{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From TensorFlow to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:25:11.634235: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-06 00:25:11.833969: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-06 00:25:11.834010: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-06 00:25:11.835176: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-06 00:25:11.943172: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-06 00:25:12.778340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:25:14.017291: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 00:25:14.087661: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 3136)              313600    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 3136)              12544     \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 3136)              0         \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 7, 7, 64)          0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTr  (None, 7, 7, 32)          51200     \n",
      " anspose)                                                        \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 7, 7, 32)          128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 7, 7, 32)          0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2D  (None, 14, 14, 16)        12800     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_2 (Bat  (None, 14, 14, 16)        64        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 14, 14, 16)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2D  (None, 28, 28, 1)         400       \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 28, 28, 1)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 390736 (1.49 MB)\n",
      "Trainable params: 384368 (1.47 MB)\n",
      "Non-trainable params: 6368 (24.88 KB)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-06 00:25:14.403967: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 00:25:14.404011: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-11-06 00:25:14.404229: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-11-06 00:25:14.404581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 00:25:14.404595: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-11-06 00:25:14.677275: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 00:25:14.677313: I tensorflow/core/grappler/devices.cc:66] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2024-11-06 00:25:14.677476: I tensorflow/core/grappler/clusters/single_machine.cc:361] Starting new session\n",
      "2024-11-06 00:25:14.677811: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-11-06 00:25:14.677831: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2211] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import onnx\n",
    "import tf2onnx\n",
    "\n",
    "# Convert the model to ONNX format\n",
    "loaded_model = tf.keras.models.load_model('../devil-in-gan/data/art-dgm-ipynb-data/benign-dcgan-mnist')\n",
    "loaded_model.summary()\n",
    "\n",
    "onnx_model, _ = tf2onnx.convert.from_keras(loaded_model)\n",
    "\n",
    "model_path = './benign-dcgan-mnist.onnx'\n",
    "onnx.save(onnx_model, model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From ONNX to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "from onnx2pytorch import ConvertModel\n",
    "\n",
    "\n",
    "# Cargar el modelo ONNX\n",
    "model_path = './benign-dcgan-mnist.onnx'\n",
    "onnx_model = onnx.load(model_path)\n",
    "\n",
    "# Convert ONNX model to PyTorch\n",
    "pytorch_model = ConvertModel(onnx_model)\n",
    "\n",
    "torch.save(pytorch_model.state_dict(), \"benign-dcgan-mnist.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvertModel from tensorflow -> onnx -> pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvertModel(\n",
      "  (MatMul_sequential_2/dense/MatMul:0): Linear(in_features=100, out_features=3136, bias=False)\n",
      "  (Mul_sequential_2/batch_normalization/batchnorm/mul_1:0): tanh()\n",
      "  (Add_sequential_2/batch_normalization/batchnorm/add_1:0): Add()\n",
      "  (LeakyRelu_sequential_2/leaky_re_lu/LeakyRelu:0): LeakyReLU(negative_slope=0.30000001192092896, inplace=True)\n",
      "  (Reshape_sequential_2/reshape/Reshape:0): Reshape(shape=[-1  7  7 64])\n",
      "  (Transpose_sequential_2/conv2d_transpose/conv2d_transpose__37:0): Transpose()\n",
      "  (ConvTranspose_sequential_2/conv2d_transpose/conv2d_transpose:0): ConvTranspose2d(64, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
      "  (BatchNormalization_sequential_2/batch_normalization_1/FusedBatchNormV3:0): BatchNormWrapper(\n",
      "    (bnu): BatchNormUnsafe(32, eps=0.0010000000474974513, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (LeakyRelu_sequential_2/leaky_re_lu_1/LeakyRelu:0): LeakyReLU(negative_slope=0.30000001192092896, inplace=True)\n",
      "  (ConvTranspose_sequential_2/conv2d_transpose_1/conv2d_transpose:0): Sequential(\n",
      "    (0): ConstantPad2d(padding=(1, 2, 1, 2), value=0)\n",
      "    (1): ConvTranspose2d(32, 16, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (BatchNormalization_sequential_2/batch_normalization_2/FusedBatchNormV3:0): BatchNormWrapper(\n",
      "    (bnu): BatchNormUnsafe(16, eps=0.0010000000474974513, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (LeakyRelu_sequential_2/leaky_re_lu_2/LeakyRelu:0): LeakyReLU(negative_slope=0.30000001192092896, inplace=True)\n",
      "  (ConvTranspose_sequential_2/conv2d_transpose_2/conv2d_transpose:0): Sequential(\n",
      "    (0): ConstantPad2d(padding=(1, 2, 1, 2), value=0)\n",
      "    (1): ConvTranspose2d(16, 1, kernel_size=(5, 5), stride=(2, 2), bias=False)\n",
      "  )\n",
      "  (Tanh_sequential_2/activation/Tanh:0): tanh()\n",
      "  (Reshape_activation): Reshape(shape=[-1 28 28  1])\n",
      ")\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Input with larger batch size than 1 not supported yet.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 25\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(pytorch_model)\n\u001b[1;32m     24\u001b[0m z \u001b[38;5;241m=\u001b[39m Variable(Tensor(np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, (\u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m100\u001b[39m))))\n\u001b[0;32m---> 25\u001b[0m \u001b[43mpytorch_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/RNA_SI/.venv_tf_v2_14_0/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/RNA_SI/.venv_tf_v2_14_0/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Projects/RNA_SI/.venv_tf_v2_14_0/lib/python3.10/site-packages/onnx2pytorch/convert/model.py:164\u001b[0m, in \u001b[0;36mConvertModel.forward\u001b[0;34m(self, *input_list, **input_dict)\u001b[0m\n\u001b[1;32m    161\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m [input_dict[key] \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_names]\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental \u001b[38;5;129;01mand\u001b[39;00m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_dim] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInput with larger batch size than 1 not supported yet.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_names, inputs))\n\u001b[1;32m    168\u001b[0m still_needed_by \u001b[38;5;241m=\u001b[39m deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeded_by)\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Input with larger batch size than 1 not supported yet."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import numpy as np\n",
    "from onnx2pytorch import ConvertModel\n",
    "from torch.autograd import Variable\n",
    "\n",
    "is_cuda_available = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if is_cuda_available else torch.FloatTensor\n",
    "\n",
    "# Cargar el modelo ONNX\n",
    "onnx_model = onnx.load(\"benign-dcgan-mnist.onnx\")\n",
    "\n",
    "# Convertir el modelo ONNX a PyTorch\n",
    "pytorch_model = ConvertModel(onnx_model)\n",
    "\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "pytorch_model.load_state_dict(torch.load(\"benign-dcgan-mnist.pth\", weights_only=True))\n",
    "pytorch_model.eval()\n",
    "\n",
    "print(pytorch_model)\n",
    "\n",
    "\n",
    "# z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], 100))))\n",
    "# pytorch_model(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_tf_v2_14_0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
