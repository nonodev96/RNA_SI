{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from PIL import Image\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CURRENT_PATH = os.path.abspath(os.getcwd())\n",
    "PARENT_DIRECTORY = os.path.dirname(CURRENT_PATH)\n",
    "TFM_PATH = os.path.join(PARENT_DIRECTORY, '')\n",
    "print(TFM_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'col1': [1,2], 'col2': [3,4]}\n",
    "df = pd.DataFrame(data)\n",
    "# display(HTML(df.to_html()))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_casia_multi_spectral_palmprintV1(row):\n",
    "    ruta_imagen = (\n",
    "        TFM_PATH\n",
    "        + f\"datasets/CASIA-Multi-Spectral-PalmprintV1/{row['Usuario']}_{row['Mano']}_{row['Banda']}_{row['Foto']}.jpg\"\n",
    "    )\n",
    "    imagen = Image.open(ruta_imagen)\n",
    "    imagen_array = np.array(imagen)\n",
    "    return imagen_array\n",
    "\n",
    "\n",
    "def load_casia_multi_spectral_palmprintV1():\n",
    "    usuarios = [f\"{i:03}\" for i in range(1, 101)]\n",
    "    manos = [\"l\", \"r\"]\n",
    "    bandas = [460, 630, 700, 850, 940, \"WHT\"]\n",
    "    fotos = [f\"{i:02}\" for i in range(1, 7)]\n",
    "    df = pd.DataFrame(\n",
    "        product(usuarios, manos, bandas, fotos),\n",
    "        columns=[\"Usuario\", \"Mano\", \"Banda\", \"Foto\"],\n",
    "    )\n",
    "\n",
    "    df[\"Imagen\"] = df.apply(lambda row: load_image_casia_multi_spectral_palmprintV1(row), axis=1)\n",
    "    display(df.head())\n",
    "\n",
    "\n",
    "load_casia_multi_spectral_palmprintV1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_file_casia_palmprintV1(row):\n",
    "    return os.path.exists(TFM_PATH + f\"datasets/CASIA-PalmprintV1/{row['Usuario']}/{row['Usuario']}_{row['Mano']}_{row['Genero']}_{row['Foto']}.jpg\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def load_image_casia_palmprintV1(row):\n",
    "    ruta_imagen = TFM_PATH + f\"datasets/CASIA-PalmprintV1/{row['Usuario']}/{row['Usuario']}_{row['Mano']}_{row['Genero']}_{row['Foto']}.jpg\"\n",
    "    imagen = Image.open(ruta_imagen)\n",
    "    imagen_array = np.array(imagen)\n",
    "    return imagen_array\n",
    "\n",
    "\n",
    "def load_casia_palmprintV1():\n",
    "    usuarios = [f\"{i:04}\" for i in range(1, 313)]\n",
    "    genero = [\"m\", \"f\"]\n",
    "    manos = [\"l\", \"r\"]\n",
    "    fotos = [f\"{i:02}\" for i in range(1, 16)]\n",
    "    # Crear el dataframe\n",
    "    df = pd.DataFrame(\n",
    "        product(usuarios, genero, manos, fotos),\n",
    "        columns=[\"Usuario\", \"Mano\", \"Genero\", \"Foto\"],\n",
    "    )\n",
    "    condition = df.apply(lambda row: check_file_casia_palmprintV1(row), axis=1)\n",
    "    df = df[condition]\n",
    "\n",
    "    df[\"Imagen\"] = df.apply(lambda row: load_image_casia_palmprintV1(row), axis=1)\n",
    "    display(df)\n",
    "\n",
    "load_casia_palmprintV1()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "img = Image.open(TFM_PATH + \"datasets/CASIA-Multi-Spectral-PalmprintV1/001_l_460_01.jpg\")\n",
    "plt.imshow(img,cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "m = nn.Bilinear(20, 30, 40)\n",
    "input1 = torch.randn(128, 20)\n",
    "input2 = torch.randn(128, 30)\n",
    "output = m(input1, input2)\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Crear un tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Convertir a NumPy\n",
    "numpy_array = tensor.numpy()\n",
    "\n",
    "# Visualizar usando Matplotlib\n",
    "plt.imshow(numpy_array, cmap='viridis')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def show_images(images) -> None:\n",
    "    n: int = len(images)\n",
    "    f = plt.figure()\n",
    "    for i in range(n):\n",
    "        # Debug, plot figure\n",
    "        f.add_subplot(1, n, i + 1)\n",
    "        plt.title(images[i].get('title'))\n",
    "        plt.imshow(images[i].get('data'))\n",
    "\n",
    "    plt.show(block=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "m = nn.Bilinear(20, 30, 40)\n",
    "input1 = torch.randn(128, 20)\n",
    "input2 = torch.randn(128, 30)\n",
    "output = m(input1, input2)\n",
    "\n",
    "out_img = output.detach().numpy()\n",
    "out_img_arr = np.squeeze(out_img)\n",
    "\n",
    "show_images(\n",
    "    [\n",
    "        {\"title\": \"numpy\", \"data\": out_img},\n",
    "        {\"title\": \"squeeze\", \"data\": out_img_arr},\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchshow as ts\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "m = nn.Bilinear(20, 30, 40)\n",
    "input1 = torch.randn(128, 20)\n",
    "input2 = torch.randn(128, 30)\n",
    "output = m(input1, input2)\n",
    "\n",
    "ts.set_color_mode('rgb')\n",
    "ts.show(output,  unnormalize='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6045, -0.1969, -0.4164,  0.4648,  1.6402, -1.0579,  1.2883,  0.2784,\n",
       "          1.2851, -1.4012,  0.4316,  1.2159,  0.6169,  0.0397, -1.4821, -0.9811,\n",
       "          0.3087,  0.0885, -1.1676, -0.3285,  1.0259,  0.1806, -1.7745, -1.0337,\n",
       "          0.4327,  0.0385,  0.0381,  0.7570,  0.7124,  0.3359, -0.1389,  0.6530,\n",
       "         -1.4402, -0.3151,  1.5652, -1.4770, -0.2590, -0.1304, -1.4664,  0.7792,\n",
       "          0.8231,  0.9012,  2.0609, -1.1325, -0.5043, -0.1015, -1.6871,  0.8658,\n",
       "          0.3348, -0.5540, -0.8563,  0.7274, -0.5741,  1.0043,  0.2864,  0.8648,\n",
       "         -0.2774,  0.1927,  1.1961, -0.4853, -0.2031,  0.1835, -0.0254,  0.5862,\n",
       "         -0.2244, -0.5164,  1.2493,  0.2654, -1.3117,  0.9570,  0.0611, -0.2807,\n",
       "         -0.2448, -1.8818,  0.7124, -0.3293,  0.0945, -0.8446,  2.0068, -0.2829,\n",
       "         -0.1627,  1.0961,  0.7378, -0.6666, -0.3399, -1.4812, -0.1479,  1.5296,\n",
       "         -0.1147,  0.5544, -0.1046, -0.8106,  1.2409, -1.1422, -1.1766,  0.0778,\n",
       "         -0.6657,  2.0609,  0.2263,  1.0053]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.normal(mean=0, std=1, size=(32, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(32, 100), dtype=float32, numpy=\n",
       "array([[ 1.0425671 , -0.3946674 ,  1.9143413 , ...,  0.39238945,\n",
       "         1.3988976 , -2.292512  ],\n",
       "       [ 1.2902411 , -0.7941994 , -0.5041753 , ..., -0.71291786,\n",
       "        -0.05493522,  0.27841508],\n",
       "       [-1.0222225 , -1.9459194 , -0.61965686, ..., -1.2329023 ,\n",
       "        -2.242136  ,  1.5528693 ],\n",
       "       ...,\n",
       "       [-0.5844678 , -0.22172196,  1.0140773 , ..., -0.21532339,\n",
       "        -1.1727126 , -0.8366579 ],\n",
       "       [ 0.100999  , -0.09992431,  1.3351063 , ...,  0.32248324,\n",
       "        -0.6542729 ,  0.9464088 ],\n",
       "       [-0.35819712,  0.8050211 , -0.55989236, ...,  0.8782153 ,\n",
       "        -0.02537242, -0.49437252]], dtype=float32)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.random.normal([32, 100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm_t310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
