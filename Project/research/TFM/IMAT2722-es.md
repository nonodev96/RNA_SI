# Assessment of geometric features for individual identification and verification in biometric hand systems

Keywords:

* Identificación del usuario
* Biometría de la mano
* Algoritmos genéticos
* Características geométricas

## Abstract

Este trabajo estudia la fiabilidad de las características geométricas para la identificación de usuarios basada en la biometría de la mano. Nuestra metodología se basa en algoritmos genéticos e información mutua. El objetivo es proporcionar un sistema de identificación de usuarios más que de clasificación. Además, se describe un método robusto de segmentación de manos para extraer la silueta de la mano y un conjunto de características geométricas en entornos difíciles y complejos. Este trabajo se centra en estudiar la importancia y la capacidad de discriminación de las características geométricas de la mano, y si son adecuadas para desarrollar una identificación biométrica robusta y fiable. Se han utilizado varias bases de datos públicas para probar nuestro método. Como resultado, el número de características necesarias se ha reducido drásticamente a partir de conjuntos de datos con más de 400 características. De hecho, se consiguen buenos índices de clasificación con unas 50 características de media, con una precisión del 100% utilizando la estrategia GA-LDA para la base de datos GPDS y del 97% para las bases de datos CASIA e IITD, aproximadamente. Para estas últimas bases de datos sin contacto, también se obtienen tasas de EER razonables.

## Introduction

La identificación de usuarios basada en la biometría es una técnica muy madura que se utiliza en muchas aplicaciones industriales, incluidos aeropuertos y sistemas informáticos. La biometría se basa en la medición de características que son únicas para un individuo, invariables en el tiempo, no invasivas y difíciles de falsificar. Dichas características incluyen: iris, huella dactilar, cara, voz y manos (Jain, Ross, & Prabhakar, 2004). En este artículo nos centramos en la biometría basada en las manos.

A pesar de la madurez de los sistemas de identificación basados en la biometría, aún queda mucho por investigar. Las manos humanas pueden utilizarse para construir sistemas biométricos basados en huellas dactilares, palmares, patrones venosos y geometría de la mano. Los sistemas de identificación basados en la geometría de la mano están adquiriendo una importancia considerable en aplicaciones de seguridad media porque aprovechan varios factores que otros rasgos biométricos no aprovechan (Sanchez-Reillo, Sanchez-Avila, & Gonzalez-Marcos, 2000). Desde el punto de vista del hardware, solo se necesitan cámaras de baja resolución, y el coste computacional de los algoritmos aplicados es relativamente escaso, por lo que es fácilmente aceptado por los usuarios. De ahí que los sistemas biométricos basados en la mano hayan atraído y motivado el interés de numerosos investigadores en los últimos años (Duta, 2009; Fong & Seng, 2009). Los estudios anteriores se centran en el uso de sistemas biométricos basados en la mano para la clasificación de usuarios. Este artículo se centra en el uso de estos sistemas para la identificación de usuarios.

En este enfoque se utilizan características geométricas, ya que son más sencillas y fáciles de calcular. A diferencia de otros trabajos de la bibliografía que intentan extraer el mayor número posible de características y aplicar posteriormente técnicas de fusión de coincidencias (Nanni y Lumini, 2009; Ross y Jain, 2003), nuestro objetivo es reducir al máximo el número de características manteniendo las mismas tasas de identificación y reconocimiento individual. Así, los rasgos seleccionados son más fáciles de interpretar, lo que implica que podemos analizar cuáles de ellos son más importantes como rasgos biométricos discriminantes. Además, podría ampliarse para determinar qué regiones de la mano son realmente adecuadas para proporcionar buenos descriptores.

Los algoritmos genéticos (AG) también se consideran estrategias evolutivas adecuadas para la selección de características en la literatura. Se adaptan bien a problemas con numerosas características (Raymer, Punch, Goodman, Kuhn y Jain, 2000) y se aplican a diferentes áreas, desde la detección de objetos (Sun, Bebis y Miller, 2004) a la detección de genes en datos de microarrays (McLachlan, Bean y Peel, 2002). Con este tipo de enfoque de selección de características, se espera alcanzar un triple objetivo: mejorar la tasa de precisión de los clasificadores; proporcionar predictores más rápidos y rentables debido a una reducción significativa del número de características; y proporcionar una mejor comprensión del proceso subyacente que generó los datos. Además, combinamos técnicas de inteligencia computacional con enfoques estadísticos como la información mutua (Guyon & Elisseeff, 2003), con el objetivo de proporcionar información sobre si los subconjuntos generados son equivalentes en términos de correlación entre las variables de cada subconjunto.

El resto de este documento se organiza como sigue: La Sección 2 ofrece una descripción detallada de los métodos existentes para la identificación de usuarios basada en la geometría de la mano. En la Sección 3 se presentan las técnicas de procesamiento de imágenes utilizadas para extraer de las imágenes de la mano, mientras que en la Sección 4 se describen los pasos necesarios para conseguir características geométricas de la mano robustas y fiables. La Sección 5 expone la metodología de este enfoque y la Sección 6 muestra los resultados experimentales sobre varias bases de datos públicas muy conocidas. En la sección 7 se analiza la utilidad y la importancia de las características seleccionadas en todas las bases de datos. La sección 8 concluye el artículo.

## Related work

En la literatura se han propuesto varios sistemas biométricos basados en la geometría de la mano, pero ninguno de ellos estudia la fiabilidad de las características geométricas a través de diferentes bases de datos de manos. Así, los rasgos más discriminantes pueden ser utilizados en posteriores aplicaciones de biometría de la mano, ya que su validez ha sido probada para diferentes imágenes. En Luque, Elizondo, López-Rubio y Palomo (2012) se proporciona una metodología novedosa para el uso de la selección de características en sistemas de biometría de la mano, basada en algoritmos genéticos e información mutua. Los autores proporcionan un conjunto de datos de características estándar que disminuye el número de características a extraer y disminuye la complejidad de todo el proceso de identificación. El número de características necesarias se redujo drásticamente de 350 a solo cinco o seis. Los resultados muestran que el método es capaz de descubrir las características geométricas de la mano más adecuadas, entre todos los datos extraídos, para realizar la tarea de clasificación. Clasificadores sencillos como el Análisis Discriminante Lineal (LDA) o k-nearest neighbours (kNN), en combinación con esta estrategia, obtienen resultados aún mejores que otros enfoques más complicados.

En Kumar y Zhou (2012) se propone un sistema de identificación de usuarios basado en imágenes dactilares. El sistema basado en una estrategia combinatoria, en puntuación combina imágenes de la vena del dedo e imágenes de baja resolución del dedo. Se utiliza un total de 6264 imágenes de 156 usuarios. Se propone un enfoque novedoso para la identificación de la vena del dedo. Aunque se encuentra en una fase inicial, se cree que las venas de los dedos permanecen estables a lo largo de los años y, por tanto, pueden proporcionar un sistema de identificación más robusto. Se obtienen niveles de precisión de la generalización dentro del 98%.

La propiedad de interoperabilidad de los dispositivos biométricos basados en la mano se presenta en González, Morales, Ferrer, Travieso y Alonso (2011). Esta propiedad proporciona una medida del rendimiento cuando un usuario se registra en un sistema biométrico utilizando un dispositivo concreto y su autenticidad se verifica en otro diferente. Esto permite actualizar fácilmente los sistemas sin necesidad de volver a registrar a los usuarios. Tras desarrollar un sistema en el que intervienen distintos dispositivos de adquisición, los autores concluyen que la interoperabilidad es posible, pero que serán necesarios parámetros más estables y la biometría de la mano para crear sistemas más robustos.

Con el objetivo de extender el uso de la biometría de reconocimiento de manos en dispositivos móviles, de Santos Sierra, Sánchez Ávila, del Pozo y Guerra Casanova (2011) desarrollaron un sistema para la segmentación de manos dada una imagen de la mano en un fondo desconocido. Se proponen estrategias de agregación multiescala para resolver este problema debido a sus resultados precisos en escenarios no restringidos y complicados, junto con sus propiedades en el rendimiento temporal. El método se evalúa con una base de datos sintética pública que contiene un total de 480.000 imágenes con diferentes fondos y entornos de iluminación. Los resultados obtenidos en términos de precisión y rendimiento temporal destacan su capacidad de ser una solución adecuada para el problema de segmentación de manos en entornos sin contacto, superando a métodos competitivos en la literatura como la segmentación de imágenes con compresión de datos con pérdida.

En Kumar y Zhou (2012) se analiza un sistema de identificación biométrica basado en imágenes dactilares. El sistema utiliza una combinación de imágenes de la vena del dedo y de huellas dactilares de baja resolución y combina estas dos pruebas mediante una novedosa estrategia de combinación a nivel de puntuación. Se proponen dos nuevos métodos de combinación a nivel de puntuación, fusión holística y no lineal. Los resultados se comparan con otros métodos de fusión por niveles de puntuación más utilizados. En este estudio, los autores utilizan una base de datos que contiene 6264 imágenes de 156 sujetos. El sistema puede realizar tanto la autenticación como el reconocimiento de usuarios.

En Zhai y Hu (2011) se propone un método de identificación de usuarios basado en la geometría de los dedos y la huella palmar. Los autores destacan la importancia de un sistema biométrico doble frente a uno único. Su sistema emplea diferentes métodos de recopilación de rasgos en vista de las diferentes áreas y diseña un emparejador jerárquico de grueso a fino de modo que se realiza un sistema de identificación multibiométrica con alta precisión de reconocimiento y buena extensibilidad. Los resultados experimentales muestran el aumento de precisión y seguridad que se obtiene utilizando la tecnología de identificación multibiométrica.

Ferrer, Vargas y Morales (2011) desarrollaron un sistema de identificación biométrica de la mano sin contacto que utiliza características geométricas y de la palma de la mano. El sistema se basaba en una combinación de imágenes visibles e infrarrojas. Las imágenes infrarrojas se binarizaron y se utilizaron como características las anchuras normalizadas del dedo índice al meñique. Las características de la palma se obtuvieron a partir de una línea ortogonal ordinal Las imágenes de la mano obtenidas de la cámara web visible se segmentaron utilizando un modelo de forma activo guiado por el contorno de la mano a partir de las imágenes infrarrojas. Se utilizaron más de 8.000 imágenes de manos de tres bases de datos públicas para comparar los enfoques de extracción de características. Se obtienen bajos niveles de error con la combinación de las imágenes.

En Jain y Duta (1999) se presenta un método de autenticación personal basado en la correspondencia deformable de las formas de las manos. Una novedad de este método es que alinea las formas de las manos antes de extraer un conjunto de características. La decisión de verificación se basa en la distancia entre las formas que se calcula durante la fase de alineación de las manos. Se ha demostrado que esta distancia es un criterio de clasificación más fiable que los conjuntos de características elaborados a mano utilizados por los sistemas anteriores. Los resultados de precisión se presentan dentro del 95,5%. Los autores sugieren que el nivel de rendimiento puede mejorarse aprendiendo una forma de plantilla de inscripción para cada usuario.

En Nishiuchi, Komatsu y Yamanaka (2009) se propone un nuevo método de identificación biométrica basado en el movimiento de flexión de los dedos. La curvatura del dedo se calcula a partir de los píxeles del borde de imágenes binarias del dedo índice. Se mide el ángulo de articulación de los dedos índice, y los perfiles de comportamiento se comparan solo cuando el ángulo de articulación de los datos comparados coincide con el de los usuarios registrados. La biometría del comportamiento es capaz de definir la comparación basándose en la continuidad temporal y en perfiles estáticos que proporcionan una gran precisión. Los experimentos muestran niveles aceptables de precisión para la identificación de usuarios.

En Sánchez-Reillo et al. (2000) se presenta otro método de identificación biométrica basado en las medidas de las manos. Las características de la mano se extraen de imágenes en color de manos colocadas sobre una plataforma. Se utilizan una serie de métodos para construir sistemas de identificación que van desde las distancias euclidianas hasta las redes neuronales. Se obtienen niveles de generalización del 97%, lo que sugiere que el sistema puede utilizarse en entornos de seguridad media y alta.

En Kumar y Ravikanth (2009) se presenta un novedoso sistema de identificación de usuarios basado en imágenes de la superficie dorsal del dedo. Los autores afirman que el patrón de textura producido por la flexión del nudillo del dedo es muy singular y convierte la superficie en un identificador biométrico distintivo. Las características geométricas del dedo pueden adquirirse simultáneamente a partir de la misma imagen e integrarse para mejorar aún más la precisión de identificación del usuario de un sistema de este tipo. Las imágenes de la superficie dorsal del dedo se normalizan para minimizar las variaciones de escala, traslación y rotación en las imágenes de los nudillos.

## Image preprocessing

Existe una gran variedad de técnicas de preprocesamiento de imágenes para la extracción de imágenes de manos y sus siluetas a partir de imágenes sin procesar, que dependen bastante de la calidad del conjunto de datos analizado. Así, deben tenerse en cuenta distintas características de la imagen, como el contraste entre el primer plano y el fondo, la posición de la mano en las imágenes, la claridad de la definición de los límites, la aparición de ayudas de posicionamiento en el sistema SanchezReillo et al. (2000), etc., para proporcionar un buen punto de partida al proceso de extracción de características.

Las restricciones del sistema de adquisición de imágenes (como la iluminación homogénea y el posicionamiento de la mano) son importantes para simplificar la fase de preprocesamiento. Así, al evitar los cambios de iluminación, se reducirá la complejidad de la tarea de binarización de la imagen. Del mismo modo, deben cumplirse algunas reglas básicas para el posicionamiento de la mano a fin de reducir la complejidad de los algoritmos, sin tener en cuenta que tales medidas resultan molestas para el usuario final. Por lo tanto, estos requisitos físicos aumentan la fiabilidad y eficacia del proceso de preprocesamiento de imágenes y también mejoran la precisión de la extracción de características y la solidez y viabilidad del sistema de reconocimiento.

No es aconsejable desarrollar algoritmos específicos de procesamiento de imágenes o una combinación de ellos para cada base de datos de manos debido a la cantidad de tiempo que se necesita para el análisis y la extracción de características en nuevos conjuntos de datos. En la literatura se han propuesto varias técnicas de preprocesamiento, pero se han diseñado específicamente para el sistema físico utilizado (Sanchez-Reillo et al., 2000). Los Userpegs se han utilizado en varias bases de datos para restringir las variaciones en la posición de la mano y la escala de la imagen, aunque pueden resultar muy incómodos para los usuarios.

En esta sección se propone un modelo general de procesamiento de imágenes basado en umbralización adaptativa y contornos activos que puede aplicarse con la mayoría de las bases de datos de manos. Para comprobar su bondad se han seleccionado tres bases de datos públicas diferentes, a saber, los conjuntos de datos de manos GPDS (Ferrer, Morales, Travieso, & Alonso, 2007), CASIA (CASIA-MSPalmprintV1) e IITD (Kumar, 2008). La base de datos GPDS Hand1 es la más sencilla para obtener una mayor precisión y robustez en las características extraídas, ya que se utilizan restricciones físicas. Esta base de datos está compuesta por 1500 imágenes de manos correspondientes a 150 individuos con 10 capturas diferentes de su mano derecha. Las imágenes han sido capturadas utilizando un escáner de escritorio sin ningún tipo de clavijas o plantillas, aunque deben cumplirse algunas reglas según la posición de la mano. Alrededor del 68% de los datos corresponden a manos masculinas y el resto a femeninas. La edad de los usuarios oscila entre los 23 y los 30 años. Al utilizar edades similares, tenemos una situación peor en la que la variación visual de la forma no es tan significativa. Las imágenes tienen una resolución de 150 ppp y 256 niveles de gris.

Las otras dos bases de datos están libres de contacto y no tienen ninguna restricción en función de la posición de las manos en el sistema. Una de ellas es la base de datos pública IIT Delhi Touchless Palmprint Database,2 que se utilizó en Kumar (2008). Este conjunto de datos es suficientemente complejo y adecuado debido al entorno semicontrolado. De esta base de datos se seleccionaron 137 usuarios con seis o más imágenes de calidad aceptable. Estos usuarios tenían entre 12 y 57 años. Las imágenes presentan diferentes variaciones en la pose de la mano y su resolución es de 800 600 en formato de mapa de bits. Estas imágenes se capturaron en un entorno interior utilizando una iluminación fluorescente circular alrededor del objetivo de la cámara.

La base de datos de imágenes multiespectrales de huellas palmares CASIA (CASIAMS-PalmprintV1) contiene imágenes de 100 personas diferentes, captadas mediante un sistema de imágenes multiespectrales. Dado que solo nos interesan las imágenes tomadas en el espectro de luz visible, utilizamos este subconjunto de imágenes de cada individuo. Cada muestra contiene seis imágenes de la palma de la mano y se guardó como archivos JPEG de 8 bits de nivel de gris mediante una cámara CCD fijada en la parte inferior del dispositivo. Para simular un sistema biométrico real se permitió un cierto grado de variación de las posturas de las manos, con el objetivo de aumentar la diversidad de las muestras intraclase. En la Fig. 1 se muestra todo el proceso de preprocesamiento junto con la información de salida necesaria. Dado que solo estamos interesados en la detección de características geométricas, no es necesaria la extracción de una región de interés (ROI).

### Binarisation

Se realiza un análisis de cada imagen para obtener un umbral adaptativo debido a la necesidad de un proceso automático general para extraer las imágenes de las manos de una gran variedad de bases de datos. El umbral se basa en los píxeles de fondo que deben detectarse previamente. En primer lugar, se aplica un filtro basado en la mediana para suavizar los picos y reducir las desagradables variaciones de píxeles.

A continuación, se aplica el operador Sobel (un algoritmo detector de bordes) a la imagen capturada para obtener la caja delimitadora que encierra la mano (Fig. 2(a)). Los bordes obtenidos corresponden principalmente a la silueta y las arrugas de la mano, ya que el fondo de la imagen suele ser la propia mano. Es necesario suavizar y filtrar la imagen de los bordes para eliminar los pequeños bordes espurios del fondo. Estos bordes se deben a la aproximación del gradiente de Sobel, que es relativamente burda, sobre todo para las variaciones de alta frecuencia en la imagen.

Como se ha indicado anteriormente, los píxeles que están fuera de la región de la mano (píxeles del fondo) se utilizan para calcular el umbral adaptativo. Estos píxeles se ordenan en función de su intensidad y se elige uno de los valores como umbral. El valor máximo de intensidad podría utilizarse como umbral (el fondo es negro), pero los píxeles espurios y las luces poco reflejadas en el fondo llevan a eliminar el 1% de los valores más altos, seleccionando la siguiente intensidad como umbral. Después se aplican operadores morfológicos para rellenar huecos y eliminar objetos espurios.

El uso de un umbral simple no siempre es suficiente para detectar completamente todas las partes de la mano. Un ejemplo de ello puede verse en la Fig. 2(b), donde el dedo pulgar no se segmenta correctamente debido a la semejanza de sus píxeles con el fondo. Por este motivo, se utilizan contornos activos para completar las regiones de la mano. Los contornos activos surgen de la observación de que es bastante difícil ajustar un contorno cuando utilizamos representaciones explícitas como, por ejemplo, los códigos en cadena. Esto se debe a que estas representaciones explícitas no son susceptibles de manipulación computacional. A la luz de esto, un contorno activo C en 2D se define como el conjunto de nivel cero de un campo escalar $\phi$:

<!-- \label{eq:1} -->
$$ C = {(x,y) \in \mathbb{R}^{2} | \phi(x,y) = 0} $$

De este modo, el problema de adaptar $C$ a los datos de entrada (en nuestro caso, la forma de la mano) se reduce a modificar $\phi$. Una elección conveniente para $\phi$ es la función de distancia con signo (SDF), que da la distancia al punto más cercano en C, con signo negativo si estamos dentro del contorno:

<!-- \label{eq:2} -->
$$ \phi({\chi},{\bf{y}})=(-1)^{\mathrm{i}({\chi},{\bf{y}})\epsilon\mathrm{int}({\zeta}))}\mathrm{min}_{({\chi}^{\prime},{\bf{y}}^{\prime})\epsilon C}||({\chi},{\bf{y}})-({\chi}^{\prime},{\bf{y}}^{\prime})|| $$

donde $I$ es la función indicadora, e $int(C)$ representa el interior de $C$. De este modo, tenemos:

$$ \phi(x,y) < 0 \Longleftrightarrow (x,y) \in int(C) $$

Aquí utilizamos el Método de Campo Esparcido (SFM) propuesto en Whitaker (1998) con el fin de reducir la complejidad computacional de almacenar y manipular $\phi$ representándolo con precisión sólo en los puntos $(x,y)$ tales que $\phi(x,y) \approx 0$, es decir, aquellos puntos más cercanos a $C$. La implementación que hemos utilizado está disponible en Lankton (2009); no permite la creación espontánea de curvas adicionales, lo cual es una ventaja, ya que las formas de la mano son conjuntos conectados. Como se observa en la Fig. 2(c), este enfoque es capaz de recuperar con precisión la silueta de la mano a pesar de los defectos de iluminación, muy frecuentes en los bordes de los dedos.

### Orientation

La mano podría tener cualquier orientación en la imagen, ya que el sistema de adquisición no proporciona ningún contacto entre la mano y cualquier superficie del dispositivo. Por lo tanto, debe tenerse en cuenta un mecanismo de alineación rotacional para mejorar la robustez de todo el sistema. En Kumar, Wong, Shen y Jain (2003) se utiliza una matriz de inercia para obtener el valor propio mayor que corresponde al eje mayor de la elipse ajustada a la región de la mano. Otro enfoque (Faundez-Zanuy, Elizondo, Ferrer-Ballester y Travieso-González, 2007) hace uso de la silueta de la mano aplicando una técnica de código en cadena sobre la imagen binaria. Así, se extraen tanto las puntas como los valles de los dedos y se realiza un proceso de rotación basado en los puntos clave del dedo corazón. En este caso, la variación máxima del ángulo se sitúa en torno al 20%.

En este trabajo, el enfoque de orientación es el mismo que el utilizado en Amayeh, Bebis, Erol y Nicolescu (2009). Se basa en operadores morfológicos de cierre y apertura con el objetivo de detectar el dedo corazón para rotar la mano, lo que requiere mucho tiempo debido al uso de un algoritmo morfológico iterativo. Suponiendo que la mano cubra la mayor parte de la imagen, los pasos principales pueden resumirse como sigue:

1. Inicializar el radio del elemento estructurante circular $D$ a un valor que esté relacionado con el tamaño de la imagen (por ejemplo, $R = 0,1 ⁄ dim_{x}$).
2. Aplicar un cierre morfológico sobre la imagen binaria, $B$, utilizando $D$ para eliminar los dedos. Además, se requiere un operador de dilatación para agrandar el puño de la mano. Esto es necesario para mantener los dedos separados en el siguiente paso.
3. Extraer los dedos separados individualmente tras restar la imagen $B$ y la imagen resultante anterior, $B'$ . También es aconsejable eliminar algunos ruidos y objetos pequeños espurios. Si no se han localizado los cinco dedos o algunos de ellos están muy próximos entre sí, el algoritmo descartará la imagen actual y solicitará una nueva captura de la mano.
4. Tras clasificar los dedos utilizando su centroide, el último paso consiste en aislar el dedo corazón (considerado el tercer dedo) y calcular la matriz de covarianza de la región para obtener el ángulo principal de rotación.

El enfoque de orientación completo se muestra en la Fig. 3. Por último, tomando una línea vertical para obtener el píxel de la mano del borde inferior y tomando una línea horizontal desde este punto para obtener la parte binaria superior, se obtiene una región binaria invariante de la mano.

## Biometrical feature extraction

En esta sección se presenta el conjunto de características de la mano extraídas de la imagen binaria. Sólo se han extraído características geométricas ya que son más sencillas de calcular y han demostrado su utilidad en problemas de reconocimiento biométrico (Faundez-Zanuy et al., 2007). Estos descriptores geométricos se describen en la Tabla 1. Cada descriptor se ha aplicado tanto a la mano como a cada dedo individualmente (Fig. 5). Cabe destacar que este proceso se realiza automáticamente analizando la silueta de la mano y la región binaria invariante de la mano obtenida en el apartado anterior. Observando la Tabla 1, podemos ver cómo los cinco primeros descriptores (*área* (a), *perímetro* (p), *anchura*, *altura* y *proporción de aspecto*) son los descriptores geométricos más típicos. Para cada dedo se calculan tres medidas de *anchura* (una por falange). La proporción de aspecto se calcula dividiendo la *anchura* por la *altura*. Si $B$ es la imagen binaria resultante que se muestra en la Fig. 3(d), la solidez puede calcularse fácilmente tras obtener el área convexa como $s = a/Convex_{B}$, la proporción de compacidad de una región se define como $c = 4p(a/p^{2})$, y la medida de rectangularidad hace uso de la caja delimitadora de la región que se va a delinear como $s = a/BoundingBox_{B}$.

Además, también se calcula un conjunto de siete momentos invariantes, denominados $Hu-moments$. Los momentos de imagen representan importantes propiedades estadísticas de una imagen y se ha demostrado su utilidad para describir objetos tras la segmentación (Liao & Pawlak, 1996). Estos siete momentos invariantes son invariantes frente a traslaciones, cambios de escala, rotaciones y transformaciones especulares. Vienen dados por las siguientes ecuaciones:

<!-- \label{eq:4} -->
$$ \varphi_{1} = \eta_{20}+\eta_{02} $$

<!-- \label{eq:5} -->
$$ \varphi_{2} = \left(\eta_{20} - \eta_{02}\right)^{2} + 4\eta_{11}^{2} $$

<!-- \label{eq:6} -->
$$ \varphi_{3} = (\eta_{30}-3\eta_{12})^{2}+\left(3\eta_{21}-\eta_{03}\right)^{2} $$

<!-- \label{eq:7} -->
$$ \varphi_{4} = (\eta_{30}+\eta_{12})^{2}+(\eta_{21}+\eta_{03})^{2} $$

<!-- \label{eq:8} -->
$$ \phi_{5} = \left(\eta_{30}-3\eta_{12}\right)\left(\eta_{30}+\eta_{12}\right)+\left[(\eta_{30}+\eta_{12})^{2}-3\left(\eta_{21}+\eta_{03}\right)^{2}\right] + (3\eta_{21}-\eta_{03})(\eta_{21}+\eta_{03})\left[3(\eta_{30}+\eta_{12})^{2}-(\eta_{21}+\eta_{03})^{2}\right] $$

<!-- \label{eq:9} -->
$$ \varphi_{6} = \left(\eta_{20} - 3\eta_{02}\right)\left[(\eta_{30}+\eta_{12})^{2}-(\eta_{21}+\eta_{03})^{2}\right] + 4\eta_{11}(\eta_{30}+\eta_{12})(\eta_{21}+\eta_{03}) $$

<!-- \label{eq:10} -->
$$ \phi_{7} = (3\eta_{21}-3\eta_{03})(\eta_{30}+\eta_{12})
\left[(\eta_{30}+\eta_{12})^{2}-3(\eta_{21}+\eta_{03})^{2}\right]+(3\eta_{12}-\eta_{03})(\eta_{21}+\eta_{03})
\left[3(\eta_{30}+\eta_{12})^{2}-(\eta_{21}+\eta_{03})^{2}\right] $$

donde $\eta_{ij}$ denota el momento invariante tanto a la traslación como a los cambios de escala dividiendo el momento central $\mu_{ij}$ por el área de la región ($\mu_{00}$) (Hu, 1962):

<!-- \label{eq:11} -->
$$ \eta_{i j}=\frac{\mu_{i j}}{\mu_{00}^{\left(1+{\frac{i+j}{2}}\right)}} $$

The central moment $\mu_{i j}$ is defined as follows:

<!-- \label{eq:12} -->
$$ \mu_{i j}=\sum_{x}\sum_{y}(x-{\bar{x}})^{i}(y-{\bar{y}})^{j}f(x,y) $$

donde $f(x, y)$ es el valor de los componentes x e y en la imagen binaria de la mano. Una silueta cerrada definida como $(x(t), y(t))$ puede representarse en términos de descriptores de Fourier, donde $t$ es la longitud de la curva desde el punto de partida. Tras seleccionar un número de puntos equidistantes, N, de la curva

<!-- \label{eq:13} -->
$$ (x(t),y(t)),\quad n=0,1,2,...,N-1 $$

it is possible to obtain the complex vector

$$ \mathbf{Z}=\mathbf{X}+i\mathbf{y} $$

donde $x = x(0),x(1),...,x(N 1)$ e $y = y(0),y(1),...,y(N 1)$. La transformada discreta de Fourier de este vector utilizando solo los primeros P descriptores de Fourier se describe como sigue

$$ \hat{Z}(u)=\frac{1}{N}\sum_{u=0}^{P-1}z(n)e x p\bigg(-\frac{2\pi n u i}{N}\bigg) $$

donde $u = 0, 1, 2, ..., N-1$ y $Z(u) = 0$, $u = P + 1, ..., N-1$ porque $\hat{Z}$ es una aproximación. Tanto la magnitud $\left\lvert Z(k) \right\rvert, k=0, 1, ..., P-1$ como la fase $arg(Z(k)), k = 0, 1, ..., P-1$ de los descriptores de Fourier se utilizan como entradas al vector de características. Se han utilizado más descriptores de Fourier para la silueta de la mano $(P = 50)$ que para la silueta de cada dedo. Por último, se calculan tres distancias robustas entre puntos interiores del contorno de la mano (Faundez-Zanuy et al., 2007). Todas estas características se representan en la Fig. 4 y se describen en la Tabla 1, donde podemos ver su posición en el vector de características (véase la Fig. 5). Por lo tanto, se extrajeron un total de 403 características de cada imagen de la mano.

## Methodology

En este trabajo se aplica una metodología que consta de dos pasos; en primer lugar, la identificación de la clase o usuario al que pertenece la muestra analizada y, en segundo lugar, la comprobación de que efectivamente la muestra es similar a otras existentes en la base de datos para ese usuario. Esta segunda fase evita que impostores ajenos al sistema puedan ser identificados como auténticos usuarios. A diferencia de otros enfoques en los que es necesario introducir información adicional sobre el usuario, como un código de identificación o una contraseña, esta metodología proporciona una actuación más sencilla e intuitiva por parte de los usuarios, ya que la imagen de la mano es la única entrada que necesita el sistema biométrico para reconocer con precisión al usuario. La Fig. 6 representa gráficamente este marco. Cada una de las dos fases se expone con más detalle en las siguientes subsecciones.

### Identification

La fase de identificación se divide en un proceso de entrenamiento inicial cuando se está registrando un nuevo usuario en el sistema biométrico y un proceso de prueba asociado a la actuación normal, donde el objetivo es determinar la identidad de una muestra de mano. La Fig. 7 muestra un esquema que integra las dos alternativas. El objetivo del módulo de entrenamiento es seleccionar el menor número de características que consigan obtener la mejor tasa de clasificación utilizando la totalidad de los datos de entrenamiento, es decir, todas las muestras asociadas a los usuarios registrados en el sistema. Se utiliza una metodología de selección de características basada en algoritmos genéticos (AG) para encontrar el mejor subconjunto de características que proporcione altos índices de precisión en la tarea de clasificación. En la parte derecha de la Fig. 7 se muestra el marco del enfoque propuesto. Aunque puede ser una propuesta que consuma mucho tiempo (dependiendo del clasificador), el AG se aplica sólo en la etapa de entrenamiento, que se realiza fuera de línea y no afecta al rendimiento en tiempo real del sistema. Esto reduce los recursos y la complejidad temporal. Por lo tanto, el principal objetivo del proceso de entrenamiento es seleccionar las variables más relevantes para definir un conjunto estándar de características, que depende en gran medida del conjunto de datos utilizado. Las condiciones del entorno y la calidad de la imagen en otros conjuntos de datos podrían cambiar y producir otro subconjunto, como podemos observar en la sección de resultados experimentales. No obstante, esta metodología de selección de características puede extrapolarse a diferentes conjuntos de datos, sin limitación en el tipo de descriptores a aplicar.

### Evolutionary strategy

Los algoritmos genéticos (Raymer et al., 2000; Sun et al., 2004) son una clase de procedimiento de optimización inspirado en los mecanismos biológicos de reproducción. En este tipo de problemas de optimización, una función de adecuación f(x) debe maximizarse o minimizarse en un espacio dado X de dimensión arbitraria. En este caso, la función de adecuación combina el objetivo de minimizar el número de características y la tasa de error de clasificación. Si el número de variables no es demasiado grande, una búsqueda exhaustiva podría ser adecuada, pero en problemas de optimización con una cantidad considerable de características, esto es inviable.

#### Encoding and initial population

Se empleó un esquema de codificación sencillo para representar en la medida de lo posible el espacio de búsqueda, en el que el cromosoma es una cadena de bits cuya longitud viene determinada por el número de características extraídas. Cada variable está asociada a un bit de la cadena. Si el $i$-ésimo bit está activo (valor 1), se selecciona la $i$-ésima característica en el cromosoma. En caso contrario, el valor 0 indica que se ignora la característica correspondiente. Cada cromosoma representa un subconjunto diferente de características que hay que evaluar. Tanto el número de características activas como la elección de las características activas se generan aleatoriamente. En todos nuestros experimentos, utilizamos una población de 100 individuos.

#### Selection, crossover and mutation

Se aplicó una estrategia de selección basada en la ruleta y el muestreo uniforme, y se eligió un valor de recuento de élite de 10 (número de cromosomas que se conservan en la siguiente generación). El cruce disperso, en el que cada bit de la descendencia se elige aleatoriamente entre los bits correspondientes de los progenitores, fue la opción elegida para combinar los progenitores de la generación anterior. La tasa de cruce se fijó en 0,8.

Además, se consideró un operador de mutación tradicional que voltea un bit específico con una tasa de probabilidad de 0,2. Se introdujo una modificación que consiste en mutar un número aleatorio de bits comprendido entre 1 y el número de características activas del individuo. Como se comprobó empíricamente que los mejores subconjuntos incluyen pocas características, este cambio evita el incremento del número de características activas en las últimas generaciones del AG.

#### Fitness function

La función de aptitud evalúa cada cromosoma de la población para poder compararlo con los demás cromosomas. El objetivo principal de la selección de subconjuntos de características es utilizar menos características para lograr el mismo o mejor rendimiento. Además, se ha descubierto que la combinación de características con poca redundancia entre ellas, es decir, que proporcionen información diferente sobre la clase objetivo y que tengan cierto parecido con ella, puede mejorar los índices de rendimiento (Chow & Huang, 2005; Peng, Long, & Ding, 2005). Por lo tanto, la función de adecuación debe contener tres términos: el error de clasificación errónea, el número de características seleccionadas y una medida de redundancia entre ellas. Para cada cromosoma, se selecciona un subconjunto de la base de datos con las características activas que queremos analizar. Para evaluar la precisión del subconjunto propuesto en términos de predicción, el conjunto de datos reducido se divide en conjuntos de entrenamiento y de prueba. El análisis discriminante lineal (LDA), k-nearest neighbours (kNN) y las máquinas de vectores de apoyo (SVM) son los clasificadores supervisados utilizados para evaluar la idoneidad del subconjunto. Las características seleccionadas dependen en gran medida de este método de clasificación utilizado en la función de adecuación. El clasificador se entrena con el primer conjunto y se valida con el segundo. El porcentaje de datos de cada conjunto se ponderó con 0,3 para el entrenamiento y 0,7 para las pruebas.

Técnicas estadísticas como la información mutua (Guo y Nixon, 2009; Leung y Gong, 2005) nos dan una idea de la correlación entre un par de características. La información mutua entre dos variables aleatorias continuas x e y viene dada por

$$ I(y,z)=\iint p(y,z)\log\left({\frac{p(y,z)}{p(y)p(z)}}\right)d y\,d z $$

donde $p(y, z)$ es la función de densidad de probabilidad conjunta de $y$ y $z$, y $p(y)$ y $p(z)$ son las funciones de densidad de probabilidad marginales de $y$ y $z$ respectivamente. La información mutua es simétrica:

$$ I(y,z)=I(z,y) $$

Además, es no negativo, y un valor cero indica que las variables son independientes. Cuanto más correlacionadas estén dos variables, mayor será su información mutua.

En un problema de clasificación como el que nos ocupa, el principal interés de la información mutua entre pares de características es evitar redundancias en el conjunto de características seleccionadas, y el de la información mutua entre cada característica y la variable de clase es maximizar la relevancia de las características seleccionadas. Las relaciones entre pares de variables se visualizan mejor trazando una matriz con toda la información mutua por pares (López-Rubio, 2010), como se ve en la Fig. 8, que representa esta información para las bases de datos GPDS e IITD. Tras analizar la matriz, se observan seis grupos compactos de características. Los rasgos de un mismo grupo están fuertemente relacionados entre sí y también con la variable de clase objetivo, que se representa en la parte inferior de la Fig. 8. A continuación se describe una medida que incorpora la correlación de las características con la clase objetivo y penaliza la redundancia entre las características seleccionadas (Peng et al., 2005):

$$ corr(\mathbf{x})={\frac{1}{t}}\sum_{i=1}^{k}\sum_{j=i+1}^{k}I(x_{j},x_{i})-{\frac{1}{k}}\sum_{j=1}^{k}I(x_{j},C) $$

donde $k$ es el número de características seleccionadas, $C$ es la clase objetiva y $t$ es el número de combinaciones entre los pares del cromosoma $x$ analizado. Por último, la función que hay que minimizar se representa de la siguiente manera:

$$ fitness(\mathbf{x}) = error(\mathbf{x}) + \lambda{\frac{k}{\mathcal{N}}} + \beta corr(\mathbf{x}) $$

donde $fitness(x)$ es el valor de fitness del subconjunto de características representado por $x$; $error(x)$ es la tasa de clasificación errónea obtenida por el clasificador (LDA, SVM o kNN) utilizando el conjunto de prueba; $N$ es el número total de características extraídas; por último, $corr(x)$ define la correlación entre las características activas del cromosoma x y la clase objetivo, con el objetivo de evitar la redundancia en el vector de características (Ec. (18)). Los valores $k$ y $b$ están en el intervalo (0,1) y se asignan empíricamente a 0,4 y 0,25, respectivamente. Por lo tanto, si dos subconjuntos alcanzan el mismo rendimiento, aunque contengan un número diferente de características, se prefiere el subconjunto con menos características. También estimulamos la mezcla de características menos redundante entre ellas, lo que se considera una buena cualidad para las tareas de clasificación. No obstante, entre los tres términos, error, tamaño del subconjunto de características y correlación, el primero es el que más nos preocupa (véase la Fig. 9).

### Verification

Supongamos que una imagen de una mano con un vector de características x se ha clasificado en la clase $i$. Entonces necesitamos un procedimiento de verificación para comprobar si esta mano pertenece realmente a la clase $i$, es decir, si la imagen corresponde a la $i$-ésima persona de la base de datos de manos. Para ello, consideramos la distancia de Mahalanobis y la distancia euclídea normalizada del vector **x** a un vector de características **y** que pertenece a las muestras de entrenamiento correspondientes a la clase $i$, es decir, sabemos con certeza que y corresponde a la $i$-ésima persona:

<!-- \label{eq:20} -->
$$ d_{Mahal}(\mathbf{X},\mathbf{y}) = {\sqrt{(\mathbf{x}-\mathbf{y})^{T} \mathbf{C}^{-1}(\mathbf{x}-\mathbf{y})}} $$

<!-- \label{eq:21} -->
$$ d_{Sumdard}(\mathbf{x},\mathbf{y})={\sqrt{\sum_{j=1}^{D}{\frac{({\boldsymbol{x}}_{j}-{\boldsymbol{y}}_{j})^{2}}{\sigma_{j}^{2}}}}} $$

donde $D$ es el número de características, $C$ es la matriz de covarianza y $r_{j}$ es la desviación estándar de la $j$-ésima característica. Tenga en cuenta que $C$ y $r_{j}$ se calculan sobre el conjunto de entrenamiento. Ahora calculamos el mínimo de estas distancias para formar un vector de dos componentes $z$ que mide lo cerca que está $x$ de la clase $i$; cuanto más bajos sean los componentes de $z$, más cerca estará la muestra de prueba $x$ de la clase $i$:

<!-- \label{eq:22} -->
$$ Z_{1}=\mathrm{min}_{{\bf y}\in C_{i}}d_{Mahal}({\bf x},{\bf y}), $$

<!-- \label{eq:23} -->
$$ Z_{2}=\mathrm{min}_{{\bf y}\in C_{i}}d_{S t a n d a r d}({\bf x},{\bf y}), $$

donde $C_{i}$ es el conjunto de muestras de entrenamiento para la clase $i$.

Por último, utilizamos un clasificador SVM para comprobar si **z** corresponde a una muestra genuina (Fig. 9), es decir, que realmente pertenece al individuo i. El conjunto de entrenamiento para el SVM se prepara calculando **z** para muestras genuinas pertenecientes a $C_{i}$ y muestras impostoras pertenecientes a $C_{k}$ con $k \neq i$.

## Experimental results

En esta sección se muestran y analizan los resultados de nuestro planteamiento. Las bases de datos CASIA, GPDS e IITD tienen 100, 144 y 137 individuos, respectivamente. El número de patrones de cada individuo oscila entre 6 muestras para los conjuntos de datos CASIA e IITD y 10 muestras para el de GPDS. En todos los experimentos se utilizó el 30% de los patrones de cada clase para el entrenamiento y el 70% para la validación. Todos los resultados experimentales presentados en este artículo se han llevado a cabo con Matlab en un PC de 32 bits con una CPU quad core de 2,40 GHz y 3 GB de RAM.

Se llevaron a cabo dos tipos de experimentos. El primero tiene como objetivo la salida de un subconjunto de selección de características factible con un alto índice de precisión. Este valor de precisión se mide como la tasa de éxito en la clasificación, es decir, el número de muestras identificadas correctamente dividido por el número total de muestras. Representa los resultados tras la fase de identificación. Así, nuestra metodología GA se combinó con tres clasificadores clásicos diferentes: el Análisis Discriminante Lineal (LDA) (Duda, Hart, & Stork, 2001), el knearest neighbours (kNN) (Cover & Hart, 1967) y el Support Vector Machine (SVM) (Cortes & Vapnik, 1995). Los dos primeros se han elegido por su popularidad en el reconocimiento de patrones y el aprendizaje supervisado y por su baja complejidad temporal. SVM es probablemente el clasificador no lineal más utilizado en la comunidad investigadora. Dado que es probable encontrar un gran número de soluciones de subconjunto con la misma precisión, el AG se ejecuta varias veces con cada clasificador. Así, se han realizado 100 ejecuciones diferentes del AG. Un tercio de ellas corresponde a cada clasificador. La tabla 2 muestra los resultados del rendimiento del AG. En esta tabla, la primera columna indica la base de datos y la segunda el número de variables de cada subconjunto correspondiente a cada ejecución del AG. La función de aptitud se define en términos del nivel de generalización obtenido por tres clasificadores (tercera columna). Las columnas cuarta, quinta y sexta muestran los resultados obtenidos con los clasificadores LDA, kNN y SVM. Corresponden a los índices de precisión (media ± std).

Cabe destacar la importante reducción del número de características, de un conjunto inicial de 403 variables a subconjuntos de características con aproximadamente 50 características de media. Es destacable la influencia del método de clasificación, tanto en los ratios de éxito en la clasificación como en el número de características seleccionadas. Así, se observa que los clasificadores más sencillos kNN y LDA requieren menos características (entre 15 y 40 aproximadamente) para alcanzar buenos niveles de clasificación, mientras que SVM necesita más información (más de 50 características) para este fin. Además, la combinación GA-LDA es la más fiable y robusta en términos de eficacia en la identificación de un individuo, obteniendo una clasificación perfecta (100%) para la base de datos GPDS, y porcentajes del 97% y 98% aproximadamente para las CASIA e ITTD, respectivamente. La importancia de las características seleccionadas por el AG puede ser local, es decir, útil sólo para un método, o global, cuando todos los clasificadores probados obtienen buenos resultados. Así, el subconjunto de características elegidas por la estrategia GA-LDA son apropiadas sólo cuando utilizamos este clasificador (LDA) en la fase de prueba para la identificación (véase la parte derecha de la Fig. 7), obteniendo peores tasas de éxito para el resto de técnicas. Por otro lado, las características seleccionadas por SVM tienen un efecto más global, ya que los resultados de clasificación para todos los clasificadores son bastante similares. Por lo tanto, la elección de las características en la estrategia GA depende del clasificador en la función de fitness.

Cabe destacar que SVM puede ajustar su vector de pesos **w** para ignorar algunos componentes (aunque estos componentes tengan una alta variabilidad), mientras que kNN da la misma importancia a todos los componentes (ya que utiliza la distancia euclídea) y LDA favorece los componentes con mayor variabilidad. En cualquier caso, hay que destacar que los clasificadores complejos, como SVM, no siempre obtienen mejores tasas de generalización que los más simples (kNN y LDA), probablemente debido a la baja cantidad de patrones en cada clase.

También se identifica la relación entre los distintos subconjuntos óptimos de características. De hecho, la Fig. 10(a), (c) y (e) muestra varios grupos significativos de características. El eje de ordenadas indica el número de ejecuciones del AG. Cada línea corresponde a un subconjunto de características diferente. Están asociadas a características de la mano y de los cinco dedos respectivamente (de izquierda a derecha). Esta información está muy relacionada con la correlación entre las características y la clase objetivo, que se obtuvo mediante la técnica de información mutua (véase la parte inferior de la Fig. 8 en la Sección 5). Las Fig. 10(b), (d) y (f) muestran que, en la mayoría de los casos, el porcentaje de características seleccionadas no supera el 10% del total, principalmente en las bases de datos CASIA e IITD para los métodos LDA y kNN. Cada punto corresponde a una ejecución diferente del AG. Como se ha comentado anteriormente, SVM requiere un mayor número de características para obtener una clasificación adecuada. Analizando la base de datos GPDS (Fig. 10(d)), se puede observar que diferentes subconjuntos de características con distinto tamaño son capaces de obtener ratios de error de clasificación cercanos al 0%. La Fig. 11 muestra tres ejecuciones obtenidas del AG aplicando diferentes estrategias (AG-LDA, AG-kNN y AG-SVM) sobre las bases de datos CASIA y GPDS. Aunque la curva de precisión es muy similar en todos los métodos, los porcentajes de coincidencia son bastante diferentes, lo que refuerza la relevancia del clasificador en el proceso de identificación.

Algunos autores consideran que las bases de datos de manos deben dividirse en las que están libres de contacto y las que tienen algún tipo de restricción (de Santos Sierra, Casanova, Avila, & Vera, 2009), ya que las características obtenidas para estas últimas son más robustas y con menor variabilidad entre muestras de un mismo individuo. Además, las bases de datos sin contacto son preferibles en términos de menor contaminación en las imágenes de las manos (las personas tienen que colocar sus manos una y otra vez en el mismo dispositivo) y de higiene, ya que las enfermedades podrían propagarse al tocar los gérmenes que quedan en las superficies (Michael, Connie, Hoe, & Jin, 2010). Utilizando la misma idea, hemos dividido la comparación cuantitativa en dos tablas; la primera está asociada a la base de datos GPDS, que tiene ciertas restricciones para colocar la mano en el sistema (Tabla 3); la otra tabla es para aquellas bases de datos que no tienen contacto o soporte en un dispositivo (CASIA e IITD, Tabla 4). La comparación, en el primer caso, se ha realizado utilizando la medida de la tasa de éxito en la clasificación, porque es la medida que otras técnicas proponen en la literatura, mientras que para las bases de datos sin contacto, utilizamos la Tasa de Error Igual (EER), considerada como el punto en el que las medidas de la Tasa de Falsa Aceptación (FAR) y la Tasa de Falso Rechazo (FRR) son iguales.

Según la Tabla 3, nuestro enfoque mejora ligeramente los resultados obtenidos por otras estrategias. Especialmente interesante es la tasa de clasificación de la combinación GA-LDA (100% de éxito), también son satisfactorios los resultados obtenidos por nuestra estrategia GA con los demás clasificadores. Es relevante que la mayoría de los enfoques utilizan un subconjunto de individuos (50), indicado en la segunda columna, mientras que nuestra metodología (GA-LDA) consigue resultados aún mejores con el conjunto de datos completo (144 individuos). La Tabla 4 refleja una comparación entre distintos enfoques que utilizan características geométricas sobre bases de datos sin contacto. Aunque la mayoría de las bases de datos son propias, pueden considerarse como una buena referencia para comparar resultados sobre conjuntos del mismo tipo, es decir, casi sin restricciones en la toma de imágenes de las manos. Así, nuestra estrategia propuesta basada en GA-LDA puede considerarse competitiva en comparación con las otras alternativas, obteniendo valores de EER entre el 4% y el 5%, tanto como bases de datos ITTD como CASIA. Debe tenerse en cuenta que el número de individuos es mayor que en los otros conjuntos de datos de otros artículos, y que el número de muestras por clase es bastante reducido (6 muestras).

## Discussion

La mayoría de las características seleccionadas por el AG tras realizar varias ejecuciones son las que están correlacionadas con la clase (véase la Sección 5, Fig. 8). La Tabla 5 presenta las diez características más seleccionadas para todas las bases de datos. Cada conjunto de datos está representado en una fila de la tabla. Las tres primeras columnas muestran información sobre las características, como el ID, la región en la que aparecen y su nombre. El gráfico de barras de la última columna divide la frecuencia de selección (cuarta columna) de cada característica según las estrategias GA-LDA, GA-kNN y GA-SVM. Por ejemplo, la distancia del dedo índice al dedo pulgar (característica cuyo ID es 11), es muy significativa para los clasificadores kNN y SVM en la base de datos GPDS, aunque su importancia para la estrategia GA-LDA es relativamente baja. Además, esta característica es la única que se selecciona entre las diez primeras características en todas las bases de datos, lo que implica que podría considerarse una característica estándar significativa en la biometría de la mano.

Existen similitudes entre las características obtenidas para los conjuntos de datos CASIA e IITD, ya que cinco de diez son las mismas para ambos conjuntos. Además, tres de estas cinco características comunes pertenecen a la región del dedo meñique. Cabe señalar que estas bases de datos no tienen contacto, lo que justifica el uso del mismo proceso de selección de características. Los momentos Hu son lo suficientemente importantes como para clasificarlos en todas las bases de datos, ya que cinco de los diez primeros rasgos pertenecen a este grupo en la base de datos GPDS, cuatro de diez en CASIA y tres de diez en IITD. Concretamente para GPDS, se seleccionan los tres primeros momentos Hu asociados al dedo índice (340-342). Los rasgos o grupos de rasgos relacionados con el clasificador SVM se seleccionan con mayor frecuencia porque esta técnica de clasificación requiere un mayor número de rasgos que kNN y LDA (véase la Tabla 2).

Para realizar un estudio sobre qué regiones de la mano tienen más probabilidades de proporcionar buenos descriptores biométricos, hemos agrupado el conjunto total de características en seis regiones, a saber: la mano en su conjunto y los dedos meñique, anular, corazón, índice y pulgar. Las características asociadas a estas regiones se definen en la Fig. 5 y en la Tabla 1 de la Sección 4. A partir de estas regiones, se calcula la frecuencia en la selección de un rasgo (en promedio) que pertenece a la región, con el objetivo de determinar la importancia de cada región como área biométrica significativa. Todos estos datos se representan visualmente en la Fig. 12(a), (c) y (e). Se puede observar que el dedo meñique es la región con más probabilidades de proporcionar rasgos, mientras que la mano la que menos. Se observa además que el pulgar es bastante descriptivo y puede ofrecer información relevante para la identificación (es la tercera región más importante en IITD y GPDS y la segunda en CASIA) a diferencia de lo que se comenta en otros trabajos (Morales, Ferrer, Alonso, & Travieso, 2008; de Santos-Sierra, Snchez-vila, del Pozo, & Guerra-Casanova, 2011). Es significativo que la región del dedo índice sea la más relevante para el conjunto de datos GPDS. Esto se debe a que las imágenes para esta base de datos de manos se toman apuntando con el dedo índice a un marcador o clavija (es una restricción del sistema), lo que implica ser la región con menor variabilidad intraclase.

Otro tipo de grupos de características, que se agrupan por su naturaleza, se describen en la Tabla 6 y se representan en la Fig. 12(b), (d) y (f). En primer lugar, se observa que los descriptores de Fourier (G5) aportan poca información. El uso de una distancia global que incluya todas las características podría ejercer un efecto más discriminante. Las tres distancias relacionadas con la mano (G4 con índices 9, 10 y 11, véase la Fig. 4 en la Sección 4) han resultado bastante robustas para todas las bases de datos, siendo el grupo más importante. Las características de los grupos G3 y G6 pueden considerarse también buenos descriptores biométricos debido a su alta frecuencia de selección. Los grupos G1 y G2 son más importantes para la base de datos GPDS, a diferencia de lo que ocurre en las de CASIA e IITD (especialmente el grupo G1). La justificación es que las imágenes, tomadas del mismo individuo en las bases de datos sin contacto, pueden obtenerse a diferentes distancias de la cámara. Por lo tanto, rasgos absolutos como el área o el perímetro (grupo G1) no son tan discriminantes como rasgos relativos como la rectangularidad y la solidez (grupo G3).

Las características con mejores índices de correlación con la clase no indican necesariamente que sean más seleccionadas que otras como variables en los subconjuntos del enfoque GA. Por ejemplo, el área de una región (características 1, 119, 176, 233, 290 y 347 de la Tabla 2), que es la característica más correlacionada con la clase, no es la variable más frecuentemente elegida para discriminar. Además, el hecho de que no exista correlación no implica la aparición de dependencia estadística (Guyon & Elisseeff, 2003). Por ejemplo, los momentos Hu aplicados a los dedos meñique e índice en la base de datos GPDS (características 169-175 y 340-346), que no tienen demasiada correlación con la clase, se seleccionan con más frecuencia que los descriptores de anchura, que tienen una correlación más alta (véase la parte inferior de la Fig. 8). Esta es una de las razones que justifican el uso de enfoques de AG frente a métodos estadísticos.

## Conclusions

Se aplica a la biometría de la mano una metodología novedosa basada en un esquema de identificación-verificación. Para ello, se presenta un enfoque de selección de características que implica la combinación de algoritmos genéticos e información mutua. Además, se describe un enfoque robusto de segmentación de manos para extraer la silueta de la mano y sus características en entornos difíciles y complejos. El objetivo de esta investigación era averiguar hasta qué punto son importantes y discriminantes las características geométricas de la mano, y si son adecuadas para desarrollar una identificación biométrica robusta y fiable.

Se han utilizado varias bases de datos públicas para probar nuestro método. Como resultado, el número de características necesarias se ha reducido drásticamente a partir de conjuntos de datos con más de 400 características. De hecho, se consiguen buenos índices de clasificación con unas 50 características de media, con una precisión del 100% utilizando la estrategia GA-LDA para la base de datos GPDS y del 97% para las bases de datos CASIA e IITD, aproximadamente. Para estas últimas bases de datos sin contacto, también se obtienen tasas de EER razonables del orden del 4-5%.

También se proporciona un estudio en profundidad de las características seleccionadas por esta propuesta, concluyendo que los descriptores de distancia de la mano y varios momentos Hu son las características más robustas y estándar que podrían utilizarse como características discriminantes en estudios posteriores. Además, la región del dedo meñique es la más adecuada para proporcionar buenos descriptores biométricos. Por lo tanto, esta metodología puede extenderse a otros sistemas biométricos con diferentes tipos de características, con el fin de mejorar la tasa de precisión en la tarea de clasificación y reducir la complejidad temporal de todo el proceso.

## Acknowledgements

Los autores agradecen los recursos informáticos, la experiencia técnica y la asistencia prestados por el centro SCBI (Supercomputación y Bioinformática) de la Universidad de Málaga.
