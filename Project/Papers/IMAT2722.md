# Assessment of geometric features for individual identification and verification in biometric hand systems

Keywords:

* User identification
* Hand biometrics
* Genetic algorithms
* Geometric features

## Abstract

This paper studies the reliability of geometric features for the identification of users based on hand biometrics. Our methodology is based on genetic algorithms and mutual information. The aim is to provide a system for user identification rather than a classification. Additionally, a robust hand segmentation method to extract the hand silhouette and a set of geometric features in hard and complex environments is described. This paper focuses on studying how important and discriminating the hand geometric features are, and if they are suitable in developing a robust and reliable biometric identification. Several public databases have been used to test our method. As a result, the number of required features has been drastically reduced from datasets with more than 400 features. In fact, good classification rates with about 50 features on average are achieved, with a 100% accuracy using the GA–LDA strategy for the GPDS database and 97% for the CASIA and IITD databases, approximately. For these last contact-less databases, reasonable EER rates are also obtained.

## Introduction

User identification based on Biometrics is a very mature technique used in many industrial applications including airports and IT systems. Biometrics are based on the measurement of characteristics which are unique to an individual, invariable through time, not invasive and difficult to counterfeit. Such characteristics include: iris, fingerprint, face, voice and hands (Jain, Ross, & Prabhakar, 2004). In this paper we focus on hand based Biometrics.

Despite the maturity of biometrics based identification systems, there is still a large amount of research taking place. Human hands can be used to build biometric systems based on fingerprints, palm prints, vein patterns and hand geometry. Hand geometry identification systems are getting a considerable importance in medium security applications because they take advantage of several factors which other biometrics traits do not (Sanchez-Reillo, Sanchez-Avila, & Gonzalez-Marcos, 2000). From the hardware viewpoint, just low resolution cameras are needed, and the computational cost of the applied algorithms is relatively scarce, so it is easily accepted by the users. Hence, hand-based biometric systems have attracted and motivated the interest of numerous researchers for the last years (Duta, 2009; Fong & Seng, 2009). Previous studies concentrate on the use of hand based biometric systems for user classification. This paper concentrates on the use of these systems for user identification.

In this approach, geometric features are used since they are simpler and easier to compute. Unlike other papers in the literature which try to extract many features as possible and apply subsequently matching fusion techniques (Nanni & Lumini, 2009; Ross & Jain, 2003), our objective is to reduce as much as possible the number of features while maintaining the same rates of individual identification and recognition. Thus, the selected features are easier to interpret, which implies we are able to analyse which of them are more important as discriminant biometrical features. Additionally, it could be further extended to determine which hand regions are really suitable to provide good descriptors.

Genetic algorithms (GAs) are also considered as suitable evolutionary strategies for feature selection in the literature. They are well adapted for problems with numerous features (Raymer, Punch, Goodman, Kuhn, & Jain, 2000), and are applied to different areas, from object detection (Sun, Bebis, & Miller, 2004) to gene detection in microarray data (McLachlan, Bean, & Peel, 2002). With this kind of feature selection approach, it is expected to achieve a threefold objective: improving the accuracy rate of the classifiers; providing faster and more cost-effective predictors because of a significant reduction of the number of features; and providing a better understanding of the underlying process that generated the data. Furthermore, we combine computational intelligence techniques with statistical approaches such as mutual information (Guyon & Elisseeff, 2003), with the aim of providing feedback about whether the subsets generated are equivalent in terms of the correlation among the variables of each subset.

The remainder of this paper is organised as follows: Section 2 provides a detailed description of existing methods for user identification based on hand geometry. Section 3 presents the image processing techniques used to extract from the hand images whereas Section 4 describes the steps needed to achieve robust and reliable geometric hand features. Section 5 sets out the methodology of this approach and Section 6 shows the experimental results over several well-known public databases. A discussion about the usefulness and significance of the selected features over all the databases is found in Section 7. Section 8 concludes the article.

## Related work

Several hand-geometry based biometric systems have been proposed in the literature but none of them study the reliability of geometric features through different hand databases. Thus, the most discriminant features can be used in further hand biometrical applications, since their validity has been proved for different images. A novel methodology for using feature selection in hand biometric systems, based on genetic algorithms and mutual information is provided in Luque, Elizondo, López-Rubio, and Palomo (2012). The authors provide a standard features dataset which diminishes the number of features to extract and decreases the complexity of the whole identification process. The number of required features were drastically reduced from 350 to just five or six. Results show that the method is capable of discovering the more suitable geometric hand features, among all the extracted data, to perform the classification task. Simple classifiers like Linear Discriminant Analysis (LDA) or k-nearest neighbours (kNN) in combination with this strategy, getting even better results than other more complicated approaches.

A user identification system based on finger images is proposed in Kumar and Zhou (2012). The score-level combination strategy based system combines finger-vein and low resolution finger images. A total of 6264 images from 156 users are used. A novel approach for finger-vein identification is proposed. Although this is at an early stage, it is believed that finger-veins remain stable throughout the years and thus can provide a more robust identification system. Accuracy levels of generalisation within the 98% are obtained.

The interoperability property of hand based biometric devices is presented in Gonzalez, Morales, Ferrer, Travieso, and Alonso (2011). This property provides a measure of the performance when a user is registered into a biometric system using a particular device and its authenticity is verified on a difference one. This allows for the systems to be easily updated without the need to re-register users. After developing a system involving different acquisition devices, the authors conclude that interoperability is possible but more stable parameters and hand biometrics will be needed to make more robust systems.

With the aim of extending the use of hand recognition biometrics into mobile devices, de Santos Sierra, Sanchez Avila, del Pozo, and Guerra Casanova (2011) developed a system for hand segmentation given a picture of the hand in an unknown background. Multiscale aggregation strategies are proposed in order to solve this problem due to their accurate results in unconstrained and complicated scenarios, together with their properties in time performance. Their method is evaluated with a public synthetic database containing a total of 480,000 images within different backgrounds and illumination environments. The results obtained in terms of accuracy and time performance highlight their capability of being a suitable solution for the problem of hand segmentation in contact-less environments, outperforming competitive methods in the literature like lossy data compression image segmentation.

A biometric identification system based on finger images is discussed in Kumar and Zhou (2012). The system uses a combination of finger-vein and low-resolution fingerprint images and combines these two pieces of evidence using a novel score-level combination strategy. Two new score-level combination methods, holistic and nonlinear fusion are proposed. Results are compared with other more commonly used score-level fusion approaches. In this study, the authors use a database containing 6264 images from 156 subjects. The system can perform both user authentication and recognition.

A user identification method based on finger geometry and palm print is proposed in Zhai and Hu (2011). The authors emphasise the importance of a double biometric system over a single one. Their system employs different methods of feature collection in view of different areas and designs a hierarchical matcher from coarse to fine so that a multi-biometric identification system is realised with high recognition accuracy and good extendibility. Experimental results show the increase in accuracy and security obtained by using multi-biometric identification technology.

A contactless hand based biometric identification system using geometric and palm features was developed by Ferrer, Vargas, and Morales (2011). The system was based on a combination of visible and infrared images. The infrared images were binarized and the normalised widths from the index to little finger were used as features. Palm features were obtained based on an orthogonal line ordinal hand images obtained from the visible webcam were segmented using an active shape model guided by the hand contour from the infrared images. Over 8000 hand images from three public databases were used in order to compare the features' extraction approaches. Low error levels are obtained with the combination of the images.

A method for personal authentication based on deformable matching of hand shapes is presented in Jain and Duta (1999). A novelty of this method is that it aligns hand shapes before extracting a feature set. The verification decision is based on the shape distance which are calculated during the hand alignment stage. This distance is shown to be a more reliable classification criterion than the hand crafted feature sets used by previous systems. Accuracy results are presented within the 95.5%. The authors suggest that the level of performance can be improved by learning an enrolment template shape for each user.

A new method of biometric identification based on the bending motion of fingers is proposed in Nishiuchi, Komatsu, and Yamanaka (2009). The finger curvature is calculated from the edge pixels of binary images of the forefinger. The joint angle of forefingers are measured, and behavioural profiles are compared only when the joint angle of compared data is consistent against registered users. Behavioural biometrics are able to define the comparison based on temporal continuity and static profiles providing high accuracy. Experiments show acceptable levels of accuracy for user identification.

Another biometric identification method based on hand measurements is presented in Sanchez-Reillo et al. (2000). Hand features are extracted from colour pictures from hands placed on a platform. A series of methods are using to build identification systems ranging from euclidean distances to neural networks. Generalisation levels of 97% are obtained which suggest that the system can be used in medium to high security environments.

A novel user identification system based on finger back surface imaging is presented in Kumar and Ravikanth (2009). The authors claim that the texture pattern produced by the finger knuckle bending is highly unique and makes the surface a distinctive biometric identifier. Geometrical features of the finger can be simultaneously acquired from the same image at the same time and integrated to further improve the user-identification accuracy of such a system. The finger back surface images are normalised to minimise scale, translation, and rotational variations in the knuckle images.

## Image preprocessing

A wide variety of image preprocessing techniques for the extraction of hand images and its silhouettes from raw images can be found, which are rather dependent on the quality of the analysed dataset. This way, different image characteristics such as the contrast between the foreground and background, the position of the hand in the images, the clarity of the boundaries' definition, the appearance of positioning aids in the system SanchezReillo et al. (2000), etc. must be taken into account in order to provide a good starting point to the feature extraction process.

The constraints for the image acquisition system (such as homogeneous lighting and hand positioning) are important to simplify the preprocessing phase. Thus, by avoiding illumination changes, the complexity of the image binarisation task will be reduced. Similarly, some basic rules for the hand positioning must be fulfilled to reduce the complexity of the algorithms, without the consideration that such measures are annoying for the enduser. Therefore, these physical requirements increase the reliability and efficiency of the image preprocessing process and also improve the accuracy of the feature extraction and the robustness and viability of the recognition system.

It is not advisable to develop specific image processing algorithms or a combination of them for each hand database due to the amount of time needed for the analysis and extraction of features on new datasets. Several preprocessing techniques have been proposed in the literature, but they have been designed specifically for the physical system used (Sanchez-Reillo et al., 2000). Userpegs have been used in several databases in order to restrict hand-pose and image scale variations although they can be highly inconvenient to the users.

A general image processing model based on adaptive thresholding and active contours that can be applied with most of the hand databases is proposed in this section. Three different public databases have been selected to check its goodness, namely, the GPDS (Ferrer, Morales, Travieso, & Alonso, 2007), CASIA (CASIA-MSPalmprintV1) and IITD (Kumar, 2008) hand datasets. The GPDS Hand database1 is the simplest to obtain a better accuracy and robustness in the extracted features since physical constraints are used. This database is composed of 1500 hand images corresponding to 150 individuals with 10 different captures of their right hand. The images have been captured using a desk-scanner without any pegs or templates, although some rules according to the position of the hand should be satisfied. About 68% of all data belongs to male hands and the rest to women. The age of the users varies from 23 to 30. By using similar ages, we have a worse situation in which the visual shape variation is not so significant. The images have a resolution of 150 dpi and 256 grey levels.

The other two databases are contact free and have no constraint according to the position of the hands in the system. One of them is the public IIT Delhi Touchless Palmprint Database,2 which was used in Kumar (2008). This dataset is complex enough and suitable because of the semi-controlled environment. A total of 137 users with six or more images with an acceptable quality were selected from this database. These users were between 12 and 57 years old. The images have different hand pose variations and their resolution is 800 600 in bitmap format. These images were captured in an indoor environment using a circular fluorescent illumination around the camera lens.

The CASIA Multi-Spectral Palmprint Image Database (CASIAMS-PalmprintV1) contains images from 100 different people, captured by using a multi spectral imaging system. Since we are only interested in images taken in the visible light spectrum, we made use of this subset of images from each individual. Each sample contains six palm images and was saved as 8 bit gray-level JPEG files by using a CCD camera fixed at the bottom of the device. In order to simulate a real biometric system a certain degree of variations of hand postures was allowed, with the aim of increasing the diversity of intra-class samples. The whole pre-processing process together with the output information required is shown in Fig. 1. Since we are only interested in geometric feature detection, the extraction of a Region of Interest (ROI) is not needed.

### Binarisation

An analysis of each image to get an adaptive threshold is performed because of the need for a general automatic process to extract the hand images from a large variety of databases. The threshold is based on background pixels which should be previously detected. First of all, a median-based filter is applied to smooth the peaks and reduce the unpleasant pixel variations.

Then, the Sobel operator (an edge detector algorithm) is applied on the captured image to get the bounding box that encloses the hand (Fig. 2(a)). The obtained edges correspond mainly to the silhouette and wrinkles of the hand, since the background of the image is typically the hand itself. The edge image needs to be smoothed and filtered to remove little spurious borders on the background. These borders are due to the Sobel gradient approximation, which is relatively crude, especially for high frequency variations in the image.

As stated above, the pixels that are outside the hand region (background pixels) are used to compute the adaptive threshold. These pixels are sorted in terms of their intensity and one of the values is chosen as the threshold. The maximum intensity value could be used as a threshold (the background is black) but spurious pixels and little reflected lights on the background lead to remove 1% of the highest values, selecting the following intensity as threshold. After this, morphological operators are applied to fill holes and remove spurious objects.

The use of a simple thresholding is not always enough to fully detect all the parts of the hand. An example of this can be seen in Fig. 2(b), where the thumb finger is not correctly segmented because of the likeness of its pixels to the background. For this reason, active contours are used to complete the hand regions. Active contours arise from the observation that it is rather difficult to adjust a contour when we use explicit representations such as chain codes, for example. This is because these explicit representations are not amenable to computational manipulation. In the light of this, an active contour C in 2D is defined as the zero-level set of a scalar field $\phi$:

<!-- \label{eq:1} -->
$$ C = {(x,y) \in \mathbb{R}^{2} | \phi(x,y) = 0} $$

This way, the problem of adapting $C$ to the input data (in our case, the hand shape) reduces to modifying $\phi$. A convenient choice for $\phi$ is the Signed Distance Function (SDF), which yields the distance to the nearest point in C, with a negative sign iff we are inside the contour:

<!-- \label{eq:2} -->
$$ \phi({\chi},{\bf{y}})=(-1)^{\mathrm{i}({\chi},{\bf{y}})\epsilon\mathrm{int}({\zeta}))}\operatorname*{min}_{({\chi}^{\prime},{\bf{y}}^{\prime})\epsilon C}||({\chi},{\bf{y}})-({\chi}^{\prime},{\bf{y}}^{\prime})|| $$

where $I$ is the indicator function, and $int(C)$ stands for the interior of $C$. This way, we have:

$$ \phi(x,y) < 0 \Longleftrightarrow (x,y) \in int(C) $$

Here we use the Sparse Field Method (SFM) proposed in Whitaker (1998) so as to reduce the computational complexity of storing and manipulating $\phi$ by accurately representing it only at the points $(x,y)$ such that $\phi(x,y) \approx 0$, i.e. those points closest to $C$. The implementation we have used is available at Lankton (2009); it does not allow the spontaneous creation of additional curves, which is an advantage, since hand shapes are connected sets. As seen in Fig. 2(c), this approach is able to accurately recover the hand silhouette in spite of illumination defects, which are very common at the edges of the fingers.

### Orientation

The hand could have any orientation in the image since the acquisition system does not provide any contact between the hand and any surface of the device. Therefore, a rotational alignment mechanism must be taken into account to improve the robustness of the entire system. An inertia matrix to obtain the larger eigenvalue that corresponds to the major axis of the ellipse fitted to the hand region is used in Kumar, Wong, Shen, and Jain (2003). Another approach (Faundez-Zanuy, Elizondo, Ferrer-Ballester, & Travieso-González, 2007) makes use of the silhouette of the hand by applying a chain code technique over the binary image. Thus, both fingers tips and valleys are extracted and a rotation process based on the key points of the middle finger is performed. Here, the maximum variation of the angle is around 20%.

In this paper, the orientation approach is the same as the one used in Amayeh, Bebis, Erol, and Nicolescu (2009). It is based on closing and opening morphological operators with the aim of detecting the middle finger to rotate the hand, which is time consuming due to the use of an iterative morphological algorithm. Under the assumption that the hand covers the majority of the image, the main steps can be summarised as follows:

1. Initialising the radius of the circular structuring element D to a value which is related to the image size (e.g. R = 0.1 ⁄ dimx).
2. Applying morphological closing on the binary image, B, using D to remove the fingers. Additionally, a dilate operator is required to enlarge the fist of the hand. This is necessary to keep the fingers separated in the following step.
3. Extract the fingers individually separated after subtracting the B image and the previous resultant image, B0 . Removing some noise and spurious small objects is also advisable. If the five fingers have not been located or some of them are very close to each other, the algorithm will discard the current image and will request a new capture of the hand.
4. After sorting the fingers using their centroid, the final step is to isolate the middle finger (considered as the third finger) and compute the covariance matrix of the region to provide the main angle of rotation.

The complete orientation approach is shown in Fig. 3. Finally, by taking a vertical line to get the bottom edge hand pixel and taking a horizontal line from this point to get the top binary part, an invariant binary hand region is obtained.

## Biometrical feature extraction

The set of extracted hand features from the binary image is presented in this section. Only geometric features have been extracted since they are simpler to compute and have proved their usefulness in biometric recognition problems (Faundez-Zanuy et al., 2007). These geometric descriptors are described in Table 1. Each descriptor has been applied both to the hand and to every finger individually (Fig. 5). It should be noted that this process is carried out automatically by analysing the hand silhouette and the invariant binary hand region obtained in the previous section. By observing Table 1, we can see how the first five descriptors (area (a), perimeter (p), width, height and aspect proportion) are the most typical geometric descriptors. Three width measures are computed for each finger (one per phalanx). The aspect proportion is computed by dividing the width by the height. Let B be the resulting binary image shown in Fig. 3(d), the solidity can be easily computed after getting the convex area as s = a/ConvexB, the compactness ratio of a region is defined as c = 4p(a/p2 ), and the rectangularity measure makes use of the bounding box of the region to be outlined as s = a/BoundingBoxB. Furthermore, a set of seven invariant moments, called Hu moments, are computed too. Image moments represent important statistical properties of an image and their usefulness have been proved to describe objects after segmentation (Liao & Pawlak, 1996). These seven invariant moments are invariant to translations, scale changes, rotations and mirror transformations. They are given by the following equations:

<!-- \label{eq:4} -->
$$ \phi_{1}=\eta_{20}+\eta_{02} $$

<!-- \label{eq:5} -->
$$ \varphi_{2}=(\eta_{20}-\eta_{02})^{2}+4\eta_{11}^{2} $$

<!-- \label{eq:6} -->
$$ \varphi_{3}=(\eta_{30}-3\eta_{12})^{2}+\left(3\eta_{21}-\eta_{03}\right)^{2} $$

<!-- \label{eq:7} -->
$$ \varphi_{4}=(\eta_{30}+\eta_{12})^{2}+(\eta_{21}+\eta_{03})^{2} $$

<!-- \label{eq:8} -->
$$ \phi_{5}=\left(\eta_{30}-3\eta_{12}\right)(\eta_{30}+\eta_{12})+\left[(\eta_{30}+\eta_{12})^{2}-3(\eta_{21}+\eta_{03})^{2}\right] + (3\eta_{21}-\eta_{03})[\eta_{21}+\eta_{03}](3(\eta_{30}+\eta_{12})^{2}-(\eta_{21}+\eta_{03})^{2}) $$

<!-- \label{eq:9} -->
$$ \varphi_{6}=[\eta_{20}-3\eta_{02}]((\eta_{30}+\eta_{12})^{2}-(\eta_{21}+\eta_{03})^{2})+4\eta_{11}(\eta_{30}+\eta_{12})(\eta_{21}+\eta_{03}) $$

<!-- \label{eq:10} -->
$$ \phi_{7}=(3\eta_{21}-3\eta_{03})(\eta_{30}+\eta_{12})
[(\eta_{30}+\eta_{12})^{2}-3(\eta_{21}+\eta_{03})^{2}]+(3\eta_{12}-\eta_{03})(\eta_{21}+\eta_{03})
[3(\eta_{30}+\eta_{12})^{2}-(\eta_{21}+\eta_{03})^{2}] $$

where gij denotes the invariant moment to both translation and changes in scale by dividing the central moment lij by the area of the region (l00) (Hu, 1962):

<!-- \label{eq:11} -->
$$ \eta_{i j}=\frac{\mu_{i j}}{\mu_{00}^{\left(1+{\frac{i+j}{2}}\right)}} $$

The central moment $\mu_{i j}$ is defined as follows:

<!-- \label{eq:12} -->
$$ \mu_{i j}=\sum_{x}\sum_{y}(x-{\bar{x}})^{i}(y-{\bar{y}})^{j}f(x,y) $$

where $f(x, y)$ is the value for the x and y components in the binary hand image. A closed silhouette defined as $(x(t), y(t))$ can be represented in terms of Fourier descriptors, where t is the length of the curve from the starting point. After selecting a number of equidistant points, N, of the curve

<!-- \label{eq:13} -->
$$ (x(t),y(t)),\quad n=0,1,2,...,N-1 $$

it is possible to obtain the complex vector

$$ \mathbf{Z}=\mathbf{X}+i\mathbf{y} $$

where $x = x(0),x(1),...,x(N  1) and y = y(0),y(1),...,y(N  1)$. The Fourier discrete transform of this vector by using just the first P Fourier descriptors is described as follows

$$ \hat{Z}(u)=\frac{1}{N}\sum_{u=0}^{P-1}z(n)e x p\bigg(-\frac{2\pi n u i}{N}\bigg) $$

where $u = 0, 1, 2, ..., N-1$ and $Z(u) = 0$, $u = P + 1, ..., N-1$ because $\hat{Z}$ is an approximation. Both the magnitude $\left\lvert Z(k) \right\rvert, k=0, 1, ..., P-1$ and the phase $arg(Z(k)), k = 0, 1, ..., P-1$ of the Fourier descriptors are used as inputs to the feature vector. More Fourier descriptors have been utilised for the hand silhouette $(P = 50)$ than for each finger silhouette. Finally, three robust distances between interior points of the hand contour are computed (Faundez-Zanuy et al., 2007). All these features are represented in Fig. 4 and described in Table 1, where we can see their position in the feature vector (see Fig. 5). Therefore, a total of 403 features were extracted from each hand image.

## Methodology

In this paper, a methodology which consists of two steps is applied; firstly, the identification of the class or user to which the analysed sample belongs, and secondly, the verification that indeed the sample is similar to other existing samples in the database for that user. This second phase prevents impostors outside the system can be identified as genuine users. Unlike other approaches where it is required to introduce additional user information such as an ID code or password, this methodology provides a simpler and more intuitive performance by the users, since the hand image is the only input needed by the biometric system to accurately recognise the user. Fig. 6 represents graphically this framework. Each one of the two phases is exposed with further details in the next subsections.

### Identification

The identification phase is divided into an initial training process when a new user is being registered in the biometric system and a testing process associated with the normal performance, where the aim is to determine the identity of a hand sample. Fig. 7 shows a scheme which integrates the two alternatives. The objective of the training module is to select the least number of features which manage to obtain the best classification rate by using the whole training data, i.e., all the samples associated to the registered users in the system. A feature selection methodology based on genetic algorithms (GAs) is used to find out the best subset of features which provide high accuracy rates in the classification task. The framework of the proposed approach is shown in the right part of the Fig. 7. Although it can be a time-consuming proposal (depending on the classifier), the GA is applied only at the training stage, which is conducted offline and does not affect the performance in real time of the system. This reduces resources and time complexity. Therefore, the main objective of the training process is to select the most relevant variables to define a standard set of features, which is largely dependent in the dataset utilised. The environment conditions and the image quality in other datasets could change and produce another subset as we can observed in the experimental results section. Nevertheless, this feature selection methodology can be extrapolated to different datasets, with no limitation in the kind of descriptors to apply.

### Evolutionary strategy

Genetic algorithms (Raymer et al., 2000; Sun et al., 2004) are a class of optimisation procedure inspired by the biological mechanisms of reproduction. In this kind of optimisation problems, a fitness function f(x) should be maximised or minimised over a given space X of arbitrary dimension. In this case, the fitness function combines the aim of minimising the number of features and the error classification rate. If the number of variables is not too large, an exhaustive search could be suitable, but in optimisation problems with a considerable amount of features, this is unfeasible.

#### Encoding and initial population

A simple encoding scheme to represent as much as possible the search space was employed, in which the chromosome is a bit string whose length is determined by the number of features extracted. Each variable is associated with one bit in the string. If the ith bit is active (value 1), then the ith feature is selected in the chromosome. Otherwise, a value of 0 indicates that the corresponding feature is ignored. Each chromosome represents a different feature subset to evaluate. Both the number of active features and the choice of what features are active, are generated randomly. In all of our experiments, we used a population size of 100 individuals.

#### Selection, crossover and mutation

A selection strategy based on roulette wheel and uniform sampling was applied, while an elite count value of 10 (number of chromosomes which are retained in the next generation) was selected. Scattered crossover, in which each bit of the offspring is chosen randomly from the corresponding bits of the parents, was the choice for combining parents of the previous generation. The crossover rate was set to 0.8.

In addition to that, a traditional mutation operator which flips a specific bit with a probability rate of 0.2 was considered. A modification which involves mutating a random number of bits between 1 and the number of active features of the individual was introduced. Since it was empirically checked that the best subsets include few features, this change avoids the increment on the number of active features in the last generations of the GA.

#### Fitness function

The fitness function assesses each chromosome in the population so that it may be ranked against all the other chromosomes. The main goal of feature subset selection is to use fewer features to achieve the same or better performance. Additionally, it has been found that the combination of features with low redundancy among them, i.e., by providing different information about the target class, and with a certain resemblance to the target class, can improve the performance rates (Chow & Huang, 2005; Peng, Long, & Ding, 2005). Therefore, the fitness function should contain three terms: the misclassification error, the number of features selected and a redundancy measure among them. For each chromosome, a subset of the database with the active features that we want to analyse is selected. To evaluate how accurate the proposed subset is in terms of prediction, the reduced dataset is split into training and testing sets. Linear Discriminant Analysis (LDA), k-nearest neighbours (kNN) and Support Vector Machines (SVM) are the supervised classifier used to assess the suitability of the subset. The selected features largely depend on this classification method used in the fitness function. The classifier is trained using the first set and validated using the second one. The percentage of data in each set was weighted by 0.3 for training and 0.7 for testing.

Statistical techniques such as mutual information (Guo & Nixon, 2009; Leung & Gong, 2005) give us an idea of the correlation between a pair of features. The mutual information between two continuous random variables x and y is given by

$$ I(y,z)=\iint p(y,z)\log\left({\frac{p(y,z)}{p(y)p(z)}}\right)d y\,d z $$

where $p(y, z)$ is the joint probability density function of y and z, and p(y) and p(z) are the marginal probability density functions of y and z respectively. The mutual information is symmetric:

$$ I(y,z)=I(z,y) $$

Moreover, it is non-negative, with a zero-value indicating that the variables are independent. The more correlated two variables are, the greater their mutual information.

In a classification problem such as the present one, the main interest in the mutual information between pairs of features is to avoid redundancies in the set of selected features, and in the mutual information between each feature and the class variable is to maximise the relevancy of the selected features. The relationships between pairs of variables are best visualised by plotting a matrix with all the pairwise mutual information (López-Rubio, 2010), as seen in Fig. 8, which represents this information for the GPDS and IITD databases. After analysing the matrix, six compact clusters of features can be observed. The features in the same group are strongly related to each other and also related to the target class variable, which is represented at the bottom of Fig. 8. A measure which incorporates the correlation of the features with the target class and penalizes the redundancy among the selected features is described as follows (Peng et al., 2005):

$$ corr(\mathbf{x})={\frac{1}{t}}\sum_{i=1}^{k}\sum_{j=i+1}^{k}I(x_{j},x_{i})-{\frac{1}{k}}\sum_{j=1}^{k}I(x_{j},C) $$

where k is the number of features selected, C is the target class and t is the number of combinations between the pairs of the chromosome x analysed. Finally, the function to be minimised is represented as follows:

$$ fitness(\mathbf{x}) = error(\mathbf{x}) + \lambda{\frac{k}{\mathcal{N}}} + \beta corr(\mathbf{x}) $$

where fitness(x) is the fitness value of the feature subset represented by x; error(x) is the rate of misclassification obtained by the classifier (LDA, SVM or kNN) using the test set; N is the total number of extracted features; finally, corr(x) defines the correlation among the active features of the chromosome x and the target class, with the aim of avoiding the redundancy in the feature vector (Eq. (18)). The k and b values are in the interval (0,1) and are empirically assigned to 0.4 and 0.25, respectively. Therefore, if two subsets achieve the same performance, while containing a different number of features, the subset with fewer features is preferred. We also stimulate the mixture of features less redundant among them, which is considered a good quality for classification tasks. Nevertheless, among the three terms, error, feature subset size, and correlation, the first one is our major concern (see Fig. 9).

### Verification

Let us assume that a hand image with feature vector x has been classified into class i. Then we need a verification procedure to check whether this hand really belongs to class i, i.e. whether the image corresponds to the ith person in the hand database. To this end we consider the Mahalanobis distance and the standardised Euclidean distance from vector **x** to a feature vector **y** which belongs to the training samples corresponding to class i, that is, we know for sure that y corresponds to the ith person:

<!-- \label{eq:20} -->
$$ d_{Mahal}(\mathbf{X},\mathbf{y}) = {\sqrt{(\mathbf{x}-\mathbf{y})^{T} \mathbf{C}^{-1}(\mathbf{x}-\mathbf{y})}} $$

<!-- \label{eq:21} -->
$$ d_{Sumdard}(\mathbf{x},\mathbf{y})={\sqrt{\sum_{j=1}^{D}{\frac{({\boldsymbol{x}}_{j}-{\boldsymbol{y}}_{j})^{2}}{\sigma_{j}^{2}}}}} $$

where D is the number of features, C is the covariance matrix and rj is the standard deviation of the jth feature. Please note that C and rj are computed over the training set. Now we compute the minimum of these distances to form a two components vector z which measures how close x is to class i; the lower the components of z, the closer the test sample x is to class i:

<!-- \label{eq:22} -->
$$ Z_{1}=\operatorname*{min}_{{\bf y}\in C_{i}}d_{Mahal}({\bf x},{\bf y}), $$

<!-- \label{eq:23} -->
$$ Z_{2}=\operatorname*{min}_{{\bf y}\in C_{i}}d_{S t a n d a r d}({\bf x},{\bf y}), $$

where $C_{i}$ is the set of training samples for class $i$.

Finally, we use a SVM classifier to check whether **z** corresponds to a genuine sample (Fig. 9), that is, one which really belongs to individual i. The training set for the SVM is prepared by computing **z** for genuine samples belonging to $C_{i}$ and imposter samples belonging to $C_{k}$ with $k \neq i$.

## Experimental results

In this section, the results of our approach are shown and analysed. The CASIA, GPDS and IITD databases have 100, 144 and 137 individuals, respectively. The number of patterns for each individual oscillates between 6 samples for the CASIA and IITD datasets and 10 samples for the GPDS one. 30% of the patterns of each class were used for training and 70% for validation in all the experiments. All the experimental results reported on this paper have been carried out with Matlab on a 32-bit PC with a quad core 2.40 GHz CPU and 3 GB RAM.

Two kinds of experiments were carried out. The first one has as its objective the output of a feasible feature selection subset with a high rate of accuracy. This accuracy value is measured as the success rate in classification, i.e. the number of samples identified correctly divided by the total number of samples. It represents the results after the identification phase. Thus, our GA methodology was combined with three different classical classifiers: the Linear Discriminant Analysis (LDA) (Duda, Hart, & Stork, 2001), the knearest neighbours (kNN) (Cover & Hart, 1967) and the Support Vector Machine (SVM) (Cortes & Vapnik, 1995). The first two of them have been chosen because of their popularity in pattern recognition and supervised learning and their low time complexity. SVM is probably the most used non-linear classifier in research community. Since it is likely to find a large number of subset solutions with the same accuracy, the GA is performed several times with each classifier. Thus, 100 different executions of the GA have been carried out. A third of them corresponds to each classifier. Table 2 shows the results of the GA performance. In this table, the first column indicates the database and the second column the number of variables in each subset corresponding to each execution of the GA. The fitness function is defined in terms of the level of generalisation obtained by three classifiers (third column). The fourth, fifth and sixth columns show the results obtained with LDA, kNN and SVM classifiers. They correspond to the accuracy rates (mean ± std).

It should be noted the important reduction on the number of features, from an initial set of 403 variables to feature subsets with approximately 50 features on average. It is remarkable the influence of the classification method, both in the success ratios in classification and in the number of features selected. Thus, it can be seen that the simpler classifiers kNN and LDA require less features (between 15 and 40 approximately) to achieve good levels of classification, whereas SVM needs more information (more than 50 features) for this purpose. Furthermore, the GA–LDA combination is the most reliable and robust in terms of effectiveness in the identification of an individual, obtaining a perfect classification (100%) for the GPDS database, and percentages of 97% and 98% approximately for the CASIA and ITTD ones, respectively. The significance of the features selected by the GA can be local, i.e., useful only for one method, or global, where all the tested classifiers get good results. Thus, the subset of features chosen by the GA–LDA strategy are appropriate only when we use this classifier (LDA) in the testing phase for identification (see right side of Fig. 7), obtaining poorer success rates for the remaining techniques. On the other hand, the features selected by SVM have a more global effect because the classification results for all classifiers are quite similar. Therefore, the choice of the features in the GA strategy depends on the classifier in the fitness function.

It is worth noting that SVM can adjust its weight vector **w** to ignore some components (even if these components have a high variability), while kNN gives the same importance to all the components (since it uses Euclidean distance) and LDA favours the components with highest variability. In any case, it must be highlighted that complex classifiers such as SVM, do not always get better generalisation rates than the simplest ones (kNN and LDA), probably because of the low amount of patterns in each class.

The relationship between different optimal feature subsets is also identified. In fact, Fig. 10(a), (c) and (e) show several significant clusters of features. The ordinate axis indicates the number of executions of the GA. Each line corresponds to a different feature subset. They are associated with features of the hand and the five fingers respectively (from left to right). This information is highly related to the correlation between the features and the target class, which was obtained by the mutual information technique (see the bottom part of the Fig. 8 in Section 5). Fig. 10(b), (d) and (f) show that, in most cases, the percentage of selected features does not exceed 10 percent of the total, mainly in the CASIA and IITD databases for LDA and kNN methods. Each point corresponds to a different execution of the GA. As discussed above, SVM requires a higher number of features in order to obtain a suitable classification. By analysing the GPDS database (Fig. 10(d)), it can be seen that different subsets of features with varying size are able to obtain misclassification ratios near 0%. Fig. 11 shows three obtained executions of the GA by applying different strategies (GA–LDA, GA–kNN and GA–SVM) over the CASIA and GPDS databases. Although, the accuracy curve is very similar in all methods, the matching rates are rather different which reinforces the relevance of the classifier in the identification process.

Some authors consider that the hand databases should be divided into those that are contact-free and those who have some kind of constraints (de Santos Sierra, Casanova, Avila, & Vera, 2009), since the characteristics obtained for these latter are more robust and with less variability among samples of the same individual. Additionally, contact-free databases are preferred in terms of less contamination in the hand images (people have to place their hands again and again in the same device) and hygiene, since illnesses could be spread by touching germs leftover on surfaces (Michael, Connie, Hoe, & Jin, 2010). Using the same idea, we have divided the quantitative comparison in two tables; the first one is associated to the GPDS database, which has some certain constraints in order to place the hand in the system (Table 3); the other table is for those databases who have no contact or support on a device (CASIA and IITD, Table 4). The comparison, in the first case, has been performed using the success rate measure in classification, because it is the measure which other techniques proposed in the literature, while for the contact-free databases, we use the Equal Error Rate (EER), considered as the point at which the False Acceptance Rate (FAR) and the False Rejection Rate (FRR) measurements are equal.

According to Table 3, our approach improves slightly the results obtained by other strategies. Particularly interesting is the classification rate for the GA–LDA combination (100% success), also satisfactory are the results obtained by our GA strategy with the other classifiers. It is relevant that the majority of the approaches use a subset of individuals (50), indicated in the second column, whereas our methodology (GA–LDA) achieves even better results with the complete dataset (144 individuals). Table 4 reflects a comparison between different approaches which use geometric features over contact-free databases. While most databases are proprietary, they can be considered as a good reference to compare results on sets of the same type, i.e. almost no restrictions on the taking of hand images. Thus, our proposed strategy based on GA–LDA can be considered competitive in comparison to the other alternatives, obtaining EER values between 4% and 5%, both as ITTD and CASIA databases. It should be noted that the number of individuals is higher than in the other datasets in other articles, and the number of samples per class is rather small (6 samples).

## Discussion

Most of the features that are selected by the GA after performing several executions, are those that are correlated with the class (see Section 5, Fig. 8). Table 5 presents the ten most selected features for all the databases. Each dataset is represented in each row of the table. The first three columns show information about the features, such as the ID, the region where they appear, and their name. The bar graph of the last column splits the frequency of selection (fourth column) of each feature according to the GA–LDA, GA–kNN and GA–SVM strategies. For instance, the distance from the index finger to the thumb finger (feature whose ID is 11), is very significant for the kNN and SVM classifiers in the GPDS database, although its importance for the GA–LDA strategy is relatively low. Moreover, this feature is the only one which is selected in the top ten features in all the databases, which implies it could be considered as a standard significant feature in hand biometrics.

There are similarities between the characteristics obtained for the CASIA and IITD datasets, since five of ten are the same for both sets. Furthermore, three of these five common features belong to the little finger region. It should be noted that these databases are contact-free, which justifies the use of the same feature selection process. The Hu moments are important enough to rank in every database, as five of the top ten features are from this group in the GPDS database, four of ten in CASIA and three of ten in IITD. Specifically for GPDS, the first three Hu moments associated to the index finger are selected (340–342). Features or groups of features related to SVM classifier are more frequently selected because this classification technique requires a higher number of traits than kNN and LDA (see Table 2).

In order to conduct a study about which regions of the hand are more likely to provide good biometric descriptors, we have grouped the total set of features in six regions, namely: the hand as a whole and the little, ring, middle, index and thumb fingers. The features associated to these regions are defined in Fig. 5 and Table 1 in Section 4. From these regions, the frequency in selecting a feature (on average) that belongs to the region is computed, with the aim of determining the importance of each region as a significant biometric area. All these data are visually represented in Fig. 12(a), (c) and (e). It can be seen that the little finger is the most likely region to provide features, while the hand the least one. It is further noted that the thumb is fairly descriptive and can offer relevant information to the identification (it is the third most important region in IITD and GPDS and the second in CASIA) unlike what is commented in other works (Morales, Ferrer, Alonso, & Travieso, 2008; de Santos-Sierra, Snchez–vila, del Pozo, & Guerra-Casanova, 2011). Significantly, the index finger region is the most relevant for the GPDS dataset. This is because the images for this hand database are taken by pointing the index finger to a marker or peg (it is a constraint of the system), which involves being the region with the lowest intra-class variability.

Another type of group of features, which are grouped by their nature, are described in Table 6 and represented in Fig. 12(b), (d) and (f). First, it is seen that the Fourier descriptors (G5) provide little information. The use of a global distance which includes all the features might exert a more discriminant effect. The three distances related to the hand (G4 with indexes 9, 10 and 11, see Fig. 4 in Section 4) have been rather robust for all databases, being the most important group. The features of the G3 and G6 groups can be considered also good biometric descriptors because of their high frequency of selection. The G1 and G2 groups are more important for the GPDS database, unlike what occurs in the CASIA and IITD ones (especially the G1 group). The justification is that the images, taken from the same individual in the contact-less databases, can be obtained at different distances from the camera. Therefore, absolute features such as the area or the perimeter (G1 group) are not as discriminating as relative features such as rectangularity and solidity (G3 group).

Features with better correlation rates with the class do not necessarily indicate that they are more selected than others as variables in the subsets of the GA approach. For instance, the area of a region (features 1, 119, 176, 233, 290 and 347 of Table 2) which is the most correlated feature with the class, is not the variable most frequently chosen to discriminate. In addition to that, the fact that there is no correlation does not imply the appearance of statistical dependence (Guyon & Elisseeff, 2003). For instance, the Hu moments applied to the little and index fingers in GPDS database (features 169–175 and 340–346), which have not too much correlation with the class, are more often selected than the width descriptors, which have a higher correlation (see the bottom part of Fig. 8). This is one of the reasons for using GA approaches as opposed to statistical methods.

## Conclusions

A novel methodology based on an identification-verification scheme is applied to hand biometrics. According to this, we present a feature selection approach which involves the combination of genetic algorithms and mutual information. Additionally, a robust hand segmentation approach to extract the hand silhouette and its features in hard and complex environments was also described. The aim of this research was to find out how important and discriminating the hand geometric features are, and if they are suitable in developing a robust and reliable biometric identification.

Several public databases have been used to test our method. As a result, the number of required features have been drastically reduced from datasets with more than 400 features. In fact, good classification rates with about 50 features on average are achieved, with a 100% accuracy using the GA–LDA strategy for the GPDS database and 97% for the CASIA and IITD databases, approximately. For these last contact-less databases, reasonable EER rates in the range of 4–5% are also obtained.

A deep study of the selected features by this proposal is also provided, concluding that the hand distance descriptors and several Hu moments are the more robust and standard features which could be used as discriminant features in subsequent studies. Moreover, the region of the little finger is the most suitable to provide good biometrical descriptors. Therefore, this methodology can be further extended to other biometric systems with different kinds of features, in order to improve the accuracy rate in the classification task and reduce the time complexity of the whole process.

## Acknowledgements

The authors thankfully acknowledge the computer resources, technical expertise and assistance provided by the SCBI (Supercomputing and Bioinformatics) center of the University of Malaga.
