\chapter*{Notación}
\addcontentsline{toc}{chapter}{\protect\numberline{}Notación}

% TODO: https://nthu-datalab.github.io/ml/slides/Notation.pdf
% TODO: https://www.mlfactor.com/notdata.html


\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Notación}   & \textbf{Definición}                                                                                               \\
            \hline
            $ \mathbb{Z} $      & Números enteros. i.e. \scriptsize{${ \mathbb{Z}  = \left\{ \ldots, -2, -1, 0, +1, +2,~\ldots \right\} }$}         \\
            $ \mathbb{Z}^{+} $  & Números enteros positivos. i.e. \scriptsize{${ \mathbb{Z}^{+}  = \left\{ 0, +1, +2,~\ldots \right\} }$}           \\
            $ \mathbb{Z}^{++} $ & Números enteros positivos sin el cero. i.e. \scriptsize{${ \mathbb{Z}^{++}  = \left\{ +1, +2,~\ldots \right\} }$} \\
            $ \mathbb{N} $      & Números naturales                                                                                                 \\
            $ \mathbb{R} $      & Números reales                                                                                                    \\
            $ \mathbb{C} $      & Números complejos                                                                                                 \\
            $ R^{n} $           & Espacio vectorial $n$-dimensional de números reales                                                               \\
            $ \epsilon $        & Para cantidades, artbitrariamente pequeñas                                                                        \\
            \hline
        \end{tabularx}
        \caption{Notación números y arrays}
        \label{tab:nnotation-part-2}
    \end{center}
\end{table}


\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Notación}                                                 & \textbf{Definición}                                                 \\
            \hline
            % Notación de vectores y matrices
            $ \mathVector{a} = [a_{i}]_{i=1, ~\ldots, n} $                    & Vectores definidos en minuscula, negrita y cursiva                  \\
            $ \mathMatrix{A} = [a_{i,j}]_{i=1, ~\ldots, n, j=1, ~\ldots, m} $ & Matrices definidas en mayúscula, negrita y cursiva                  \\
            $ \mathTensor{A} $                                                & Tensores definidos en mayúscula, negrita y en estilo sans serif     \\
            \hline
            % Indices de vectores y matrices
            ${ \mathVector{a}_{i} }$                                          & Elemento $i$ del vector $\mathVector{a}$, empezando el índice por 1 \\
            ${ \mathMatrix{A}_{i,j} }$                                        & Elemento ($i,j$) de la matriz $\mathMatrix{A}$                      \\
            ${ \mathMatrix{A}_{i,:} }$                                        & Fila $i$ de la matriz $\mathMatrix{A}$                              \\
            ${ \mathMatrix{A}_{:,j} }$                                        & Columna $j$ de la matriz $\mathMatrix{A}$                           \\
            ${ \mathTensor{A}_{i,j,k} }$                                      & Elemento ($i,j,k$) 3D del tensor $\mathTensor{A}$                   \\
            ${ \mathTensor{A}_{:,:,k} }$                                      & Desplazamiento 2D del Tensor 3D                                     \\
            \hline
        \end{tabularx}
        \caption{Notación de índices para vectores, matrices y tensores}
        \label{tab:nnotation-part-v-1}
    \end{center}
\end{table}

\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Notación}     & \textbf{Definición}                                                                                                  \\
            \hline

            % Vectores, matrices y tensores especiales
            $ I_{n} $             & Matriz identidad de tamaño $ n \times n $                                                                            \\
            $ 0_{n,m} $           & Matriz de ceros de tamaño $ n \times m $                                                                             \\
            $ \underline{0}_{n} $ & Vector de ceros de tamaño $ n $                                                                                      \\
            $ 1_{n,m} $           & Matriz de unos de tamaño $ n \times m $                                                                              \\
            $ \underline{1}_{n} $ & Vector de unos de tamaño $n $                                                                                        \\
            $ e_{i} $             & Vector estandar o vector canonico.\newline i.e. \scriptsize{${ v_{x} = (1,0,0), v_{y} = (0,1,0), v_{z} = (0,0,1)} $} \\
            \hline
        \end{tabularx}
        \caption{Notación de vectores, matrices y tensores especiales}
        \label{tab:nnotation-part-v-2}
    \end{center}
\end{table}




\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Símbolo}                                                                                                     & \textbf{Definición}                                                                         \\
            \hline
            % Operaciones tipicicas
            $ \mathMatrix{A}^{\dagger} $                                                                                         & Traspuesta de la matriz $\mathbf{A}$                                                        \\
            $ \text{rk}\left(\mathMatrix{A}\right) $                                                                             & Rango de la matriz $\mathbf{A}$                                                             \\
            $ \text{tr}\left(\mathMatrix{A}\right) $                                                                             & Traza de la matriz $\mathbf{A}$                                                             \\
            $ \text{det}\left(\mathMatrix{A}\right) $                                                                            & Determinante de la matriz $\mathbf{A}$                                                      \\
            $ \text{Im}\left(\Phi\right) $                                                                                       & Imagen del mapeo lineal $\Phi$                                                              \\
            $ \text{ker}\left(\Phi\right) $                                                                                      & Núcleo (espacio nulo) de un mapeo lineal $\Phi$                                             \\
            % $ \text{span}\left[\mathbf{b}_{1}\right] $                        & Sistema generador de $\mathbf{b}_{1}$                                                                                \\
            \hline
            % Notación matemática de operaciones con vectores y matrices
            $ {\lvert \cdot \rvert} $                                                                                            & Determinante o valor absoluto                                                               \\
            $ {\lVert x \rVert}_{p} $                                                                                            & Norma $L^{p}$ de $x$                                                                        \\
            $ {\lVert x \rVert} $                                                                                                & Norma $L^{2}$ de $x$                                                                        \\
            $ {\Vert \underline{x} - \underline{y} \Vert}_{q} $                                                                  & Distancia en la misma dimensión entre $\underline{x}$ e $\underline{y}$                     \\
            $ \underline{x} \odot \underline{m} $                                                                                & Operación por elementos de los vectores o matrices                                          \\
            $ \left\langle \underline{z}, \underline{y} \right\rangle = \underline{z}' \underline{y} = \sum_{j=1}^{N}{z_j y_j} $ & Producto escalar de vectores por columnas $\underline{z}, \underline{y} \in \mathbb{R}^{N}$ \\
            \hline
        \end{tabularx}
        \caption{Notación de operaciones con vectores y matrices}
        \label{tab:nnotation-part-operations-v-m}
    \end{center}
\end{table}


\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Notación}                                                                                                                                                                                                                 & \textbf{Definición}                                                                                   \\
            \hline
            % Notación matemática de gradientes, funciones a minimizar, operador
            % $ g \circ f $                          & Función composiciones (g después de f)                                                                                        \\
            $ f: \mathbb{A} \rightarrow \mathbb{B} $                                                                                                                                                                                          & Una función $f$ con dominio $\mathbb{A}$ y rango $\mathbb{B}$                                         \\
            $ \nabla f = \left( \frac{\partial f}{\partial x}, \frac{\partial f}{\partial y}, \frac{\partial f}{\partial z} \right) $                                                                                                         & Gradiente, es un vector que indica la dirección de mayor pendiente de una superficie en un punto dado \\
            $ \nabla f(\mathbf{a}) \in \mathbb{R}^{n} $                                                                                                                                                                                       & Gradiente de la función $f: \mathbb{R}^{n} \rightarrow \mathbb{R}$ con entrada $\mathbf{a}$           \\
            $ \nabla \cdot f =  \frac{\partial f}{\partial x} + \frac{\partial f}{\partial y} + \frac{\partial f}{\partial z} $                                                                                                               & Divergencia                                                                                           \\
            $ \nabla \times f =  \left( \frac{\partial f}{\partial y} - \frac{\partial f}{\partial z}, \frac{\partial f}{\partial z} - \frac{\partial f}{\partial x}, \frac{\partial f}{\partial x} - \frac{\partial f}{\partial y}  \right)$ & Rotación                                                                                              \\
            $ f_{*} = \text{min}_x~f(x) $                                                                                                                                                                                                     & El valor de función más pequeño de $f$                                                                \\
            $ {x}_x \in \text{arg min}_{x}~f(x) $                                                                                                                                                                                             & El valor $x_{*}$ (conjunto de valores) que minimiza $f$                                               \\
            \hline
        \end{tabularx}
        \caption{Notación de funciones}
        \label{tab:nnotation-part-functions}
    \end{center}
\end{table}


\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Notación}                                                                & \textbf{Definición}                                                                                                                                                             \\
            \hline % Notación de ANN (redes neuronales, conjunto de datos, entrada, salida, clases, etc)
            $ \mathcal{X} $                                                                  & Conjunto de datos, donde $\mathcal{X} \in \mathbb{R}^{N}$\newline{} La dimensión de la matriz de características es ${\mathcal{X} = I \times K}$                                \\
            $ N $                                                                            & Dimensión del espacio muestral de entrada $\mathcal{X}$                                                                                                                         \\
            $ \left\{x_{1}, x_{2}, \ldots ,x_{n}\right\} $                                   & Conjunto con $n$ elementos                                                                                                                                                      \\
            ${T~\text{o}~\mathbb{X} = \left\{x^{(i)}, y^{(i)}\right\}}$                      & Conjunto de datos de entrenamiento ${D \subset \mathcal{X}}$                                                                                                                    \\
            ${V~\text{o}~\mathbb{X}^{\prime} = \left\{x^{\prime(i)}, y^{\prime(i)}\right\}}$ & Conjunto de datos de validación ${H \subset \mathcal{X}}$                                                                                                                       \\
            $ I $                                                                            & Número de instancias, registros u observaciones                                                                                                                                 \\
            $ K $                                                                            & Número de atributos, características, entradas o predictores                                                                                                                    \\
            $ \mathcal{Y} $                                                                  & Conjunto de clases del conjunto de datos $\mathcal{X}$, esto es, $\textit{K} = \lvert \mathcal{Y} \rvert$. \newline i.e. \scriptsize{${ \mathcal{Y} = \{1,2,...,\textit{K}\}}$} \\
            % $ \mathcal{D} $                                                       & Subconjunto para el entrenamiento, donde $\mathcal{D} \subset \mathcal{X}$                                                                                                      \\
            % $ H $                                                                 & Subconjunto de validación, este conjunto contiene muestras de todas las clases                                                                                                     \\
            $ \eta $                                                                         & Tasa de aprendizaje                                                                                                                                                             \\
            $ \hat{y} $                                                                      & Predicción del modelo                                                                                                                                                           \\
            $ \theta $                                                                       & Parámetros del modelo                                                                                                                                                           \\
            $ \mathcal{L} $                                                                  & Función de perdida                                                                                                                                                              \\
            $ \phi ,\varphi $                                                                & Función de activación                                                                                                                                                           \\
            $ f\left(\cdot\right) $                                                          & Modelo                                                                                                                                                                          \\
            $ {c}\left(\cdot\right) $                                                        & Modelo clasificador                                                                                                                                                             \\
            $ {p}\left(\cdot\right) $                                                        & Modelo predictor                                                                                                                                                                \\
            \hline
        \end{tabularx}
        \caption{Notación de \textit{Machine Learning}}
        \label{tab:nnotation-part-ml}
    \end{center}
\end{table}

\begin{table}[H]
    \begin{center}
        \begin{tabularx}{\textwidth}{|r|X|}
            \hline
            \textbf{Notación} & \textbf{Definición}                                 \\
            \hline % Notación de GANS (redes neuronales adversariales)
            $ x $             & Entrada original (limpia, sin modificar) de un dato \\
            $ x^{\prime} $    & Dato adversarial                                    \\
            $ y^{\prime} $    & Clase objetivo de ejemplo adversario                \\
            $ \delta $        & Perturbación                                        \\

            % $ \hat{p}\left(\cdot\right) $ & Modelo predictor                                    \\
            % $ \hat{c}\left(\cdot\right) $ & Modelo inferido clasificador                                 \\
            % $ \Delta, \epsilon  $ & Restricción en la perturbación                                                   \\
            \hline
        \end{tabularx}
        \caption{Notación de \textit{GAN}}
        \label{tab:nnotation-part-gans}
    \end{center}
\end{table}



% \newpage
% \KOMAoptions{paper=landscape,pagesize}
% \recalctypearea
% \section{This is my Landscape Page}
% Text in my landscape section\footnote{Footnote in Landscape}

% \newpage
% \KOMAoptions{paper=portrait,pagesize}
% \recalctypearea


% \begin{enumerate}
%     \item $\mathcal{Y}$ es el conjunto de clases del conjunto de datos $\mathcal{X}$.
%     \item $\hat{c}(\mathcal{X})$ es el término que nos referimos al clasificador del conjunto $\mathcal{X}$
%     \item $P(C|A)$ nos referimos a la probabilidad condicionada ($P$) de la clase ($C$) con los atributos ($A$).
%           % \item $ a \gg b$ `a' mucho mayor que `b'.
%           % \item $ a \ll b$ `a' mucho menor que `b'.
% \end{enumerate}


\chapter*{Teoremas}
\addcontentsline{toc}{chapter}{\protect\numberline{}Teoremas}

% Maldición de la dimensionalidad -> clasificación basaa en naive bayes 
% Clasificador de Naïve Bayes
% Cada atributo como una variables independiente de la case
% Naïve significa ingenuo

\begin{theorem}[Bayes]
    \label{theorem:bayes}
    Sean $C$, $A$ dos eventos, y $P(C|A)$ la probabilidad de $C$ dependiente de $A$. Entonces.
    \[ P(C|A) = \frac{P(C|A) P(C)}{P(A)} \]
\end{theorem}

% http://www.lcc.uma.es/~jmortiz/archivos/Tema4.pdf
\begin{theorem}[Convergencia de perceptrón]
    \label{theorem:ConvergenciaRosenblatt}
    Si el conjunto de patrones de entrenamiento $ \{x^{1}, z^{1}\}, \{x^{2}, z^{2}\}, \cdots, \{x^{n}, z^{n}\} $ es linealmente separable entonces el Perceptrón simple encuentra una solución en un número finito de iteraciones, es decir, consigue que la salida de la red coincida con la salida deseada para cada uno de los patrones de entrenamiento.
\end{theorem}