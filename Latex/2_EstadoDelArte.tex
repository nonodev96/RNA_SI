\chapter{ANTECEDENTES Y ESTADO DEL ARTE}
\label{ch:2}
% ==============================================================================================================
\section{Introducción}

\section{Antecedentes}

\subsection{Historia, línea temporal}

% \begin{table}[t]
%     \begin{center}
%         \begin{tabular}{l|l}\hline
%             1943   & Threshold Logic Unit (TLU) \cite{mcculloch1943logical}                         \\
%             1958   & Perceptron \cite{rosenblatt1958perceptron}                                     \\
%             1965   & Multilayer Perceptron \cite{baum1988capabilities}                              \\
%             1980’s & Neuronas Sigmoidales                                                           \\
%             ~      & Feedforward neural network (FNN) \cite{rumelhart1985learning}                  \\
%             ~      & Backpropagation \cite{rosenblatt1962principles,etde_5080493,lecun1985learning} \\
%             1985   & Boltzmann Machine \cite{ACKLEY1985147}                                         \\
%             1989   & Convolutional neural networks (CNN) \cite{lecun1989backpropagation}            \\
%             ~      & Recurent neural networks (RNN)                                                 \\
%             1997   & Long short term memory (LSTM)                                                  \\
%             2006   & Deep Belief Networks (DBN) \cite{hinton2006fast}                               \\
%             ~      & Restricted Boltzmann Machine \cite{hinton2006reducing}                         \\
%             ~      & Encoder / Decoder (Auto-encoder) \cite{hinton2006reducing}                     \\
%             2014   & Generative Adversarial Networks (GAN) \cite{6294131,goodfellow2014generative}  \\\hline
%         \end{tabular}
%         \caption{Hitos en las redes neuronales artuficiales}
%         \label{tab:fruta}
%     \end{center}
% \end{table}


\begin{vtimeline}[timeline color=cyan!80!blue, add bottom line, line offset=2pt, use timeline header,timeline title={Hitos de las redes neuronales artificiales}]
    1943   & Threshold Logic Unit (TLU) \cite{mcculloch1943logical}                         \endlr
    1958   & Perceptron \cite{rosenblatt1958perceptron}                                     \endlr
    1965   & Multilayer Perceptron \cite{baum1988capabilities}                              \endlr
    1980’s & Neuronas Sigmoidales                                                           \endlr
    ~      & Feedforward neural network (FNN) \cite{rumelhart1985learning}                  \endlr
    ~      & Backpropagation \cite{rosenblatt1962principles,etde_5080493,lecun1985learning} \endlr
    1985   & Boltzmann Machine \cite{ACKLEY1985147}                                         \endlr
    1989   & Convolutional neural networks (CNN) \cite{lecun1989backpropagation}            \endlr
    ~      & Recurent neural networks (RNN)                                                 \endlr
    1997   & Long short term memory (LSTM) \cite{Hochreiter1997LongSM}                                            \endlr
    2006   & Deep Belief Networks (DBN) \cite{hinton2006fast}                               \endlr
    ~      & Restricted Boltzmann Machine \cite{hinton2006reducing}                         \endlr
    ~      & Encoder / Decoder (Auto-encoder) \cite{hinton2006reducing}                     \endlr
    2014   & Generative Adversarial Networks (GAN) \cite{6294131,goodfellow2014generative}  \endlr
\end{vtimeline}

Las \gls{RNN} se basaron en el trabajo de David Rumelhart \cite{rumelhart1985learning}

% \begin{vtimeline}[description={text width=0.75\linewidth},
%         use timeline header,
%         timeline color=black,
%         timeline title={Hitos de las redes neuronales artificiales}]
%     1943   & Threshold Logic Unit (TLU) Neuronas de McCulloch y Pitts \cite{mcculloch1943logical}   \endlr
%     1958   & Perceptron \cite{rosenblatt1958perceptron}                                             \endlr
%     1965   & Multilayer Perceptron \cite{baum1988capabilities}                                      \endlr
%     1980’s & Neuronas Sigmoidales                                                                   \endlr
%     ~      & Feedforward neural network (FNN) \cite{rumelhart1985learning}                          \endlr
%     ~      & Backpropagation \cite{rosenblatt1962principles,etde_5080493,lecun1985learning}         \endlr
%     % ~      & Adaptative resonance thory (ART) \cite{grossberg1987competitive} \endlr
%     1989   & Convolutional neural networks (CNN) \cite{lecun1989backpropagation}                    \endlr
%     ~      & Recurent neural networks (RNN)                                                         \endlr
%     ~      & Boltzmann Machine or Recurent neural networks estocastic (RNN)   \cite{}              \endlr
%     1997   & Long short term memory (LSTM)                                                          \endlr
%     2006   & Deep Belief Networks (DBN) \cite{hinton2006fast}                                       \endlr
%     ~      & Restricted Boltzmann Machine                                                           \endlr
%     ~      & Encoder / Decoder (Auto-encoder)                                                       \endlr
%     2014   & Generative Adversarial Networks (GAN) \cite{goodfellow2014generative}                  \endlr
% \end{vtimeline}

\subsection{Historia}

\subsection{Hitos}

\section{Estado del arte}

\subsection{Defensas contra los ataques adversarios}

\subsection{Privacidad}

\subsection{Explicabilidad}

\subsection{Normativa y estándares}
% https://eur-lex.europa.eu/resource.html?uri=cellar:e0649735-a372-11eb-9585-01aa75ed71a1.0008.02/DOC_1&format=PDF
% https://eur-lex.europa.eu/resource.html?uri=cellar:e0649735-a372-11eb-9585-01aa75ed71a1.0008.02/DOC_2&format=PDF

% Segun la unión europea toda la seguridad es este apartado :ok: 
% (51) La ciberseguridad es fundamental para garantizar que los sistemas de IA resistan a las actuaciones de terceros maliciosos que, aprovechando las vulnerabilidades del sistema, traten de alterar su uso, conducta o funcionamiento o de poner en peligro sus propiedades de seguridad. Los ciberataques contra sistemas de IA pueden dirigirse contra elementos específicos de la IA, como los conjuntos de datos de entrenamiento (p. ej., contaminación de datos) o los modelos entrenados (p. ej., ataques adversarios), o aprovechar las vulnerabilidades de los elementos digitales del sistema de IA o la infraestructura de TIC subyacente. Por lo tanto, para asegurar un nivel de ciberseguridad adecuado a los riesgos, los proveedores de sistemas de IA de alto riesgo deben adoptar medidas adecuadas teniendo también en cuenta, cuando proceda, la infraestructura de TIC subyacente.

\subsection{Métodos técnicos}
\begin{itemize}
    \item Arquitecturas para una IA fiable.
    \item Ética y estado de Derecho desde el diseño.
    \item Métodos de explicación.
    \item Realización de ensayos y validación.
    \item Indicadores de calidad del servicio.
\end{itemize}

\subsection{Métodos no técnicos}
\begin{itemize}
    \item Normativa.
    \item Códigos de conducta.
    \item Normalización.
    \item Certificación.
    \item Marcos de gobernanza.
\end{itemize}

\section{Desafíos futuros}


\section{Conclusión}




% https://www.youtube.com/@felipebravom

