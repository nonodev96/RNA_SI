\chapter{INTRODUCCIÓN}
\label{ch:1}

% Descripción de los objetivos del aprendizaje adversario:
\section{Introducción}

El objetivo principal de este trabajo es el análisis de los distintos tipos de ataques y defensas que se pueden aplicar a un proceso de aprendizaje automático, nos referimos principalmente al aprendizaje profundo.
Este trabajo tratará principalmente de clasificar y explorar la seguridad que cuentan los modelos de \gls{AI} actuales.
Existen una gran variedad de modelos y objetivos en redes neuronales, los ataques que se pueden hacer sobre estos modelos están orientados en las siguientes categorías (evadir, envenenar, explorar o denegar) el modelo.

Debemos comprender que debemos saber que la seguridad repercute en todo el proceso de creación del modelo, desde la recogida de los datos, tratamiento, diseño y creación del modelo.
Un ataque puede estar dirigido al conjunto de datos con el que se entrenará el modelo o a la red neuronal una vez entrenada.
Además, un ataque puede dirigirse a descubrir muestras que produzcan resultados erróneos, por lo que los posibles vectores de ataque son muy variados y complejos.

La idea de hacer robustos los modelos es que las defensas detecten ataques a la vez que se mejora la solidez del aprendizaje, para no cometer fallos al introducir valores anómalos.

Cada uno de estos tipos de ataques tiene su nomenclatura y debe definirse correctamente, ya que de lo contrario puede ser muy ambiguo el tipo de ataque que se está realizando, el objetivo que busca y los métodos que están empleando.

Lo que buscaremos en este trabajo será definir, analizar y estructurar los distintos tipos de ataques y sus posibles defensas, con el objetivo final de proteger y defender los modelos de inteligencia artificial para hacerlos más robustos.
Además de la construcción de una guía que pueda orientar a modelos más seguros y éticos.


\section{Motivación}

En la última década, se han logrado significativos avances en el campo de la inteligencia artificial. Sin embargo, a lo largo de este proceso, como suele ser habitual, se ha descuidado  aspectos cruciales relacionados con la seguridad. Esto ha dado lugar a la creación de productos que implementan la inteligencia artificial, pero presentan vulnerabilidades, riesgos potenciales, como redes neuronales poco robustas, filtraciones de datos, incumplimiento normativo, modelos que presentaban respuestas ofensivas, discriminantes ante etnias, etc. Además de presentar poca o ninguna explicabilidad de los resultados que presentan.

Esto lleva a muchos problemas de seguridad y riesgos que pueden afectar a productos que apliquen inteligencia artificial sin las medidas de adecuadas.

\begin{itemize}
    \item Alineación de la inteligencia artificial.
    \item Recopilación de datos.
    \item Bias y discriminación.
    \item Modelos poco robustos.
    \item Transparencia y explicabilidad.
    \item Escala de los modelos.
    \item Cumplimiento legal y normativo.
    \item Actualización continua.
    \item Detección de usos malintencionados.
\end{itemize}

Esto ha llevado a la creación de regulaciones de la inteligencia artificial que son muy vagas en sus conceptos de implementación.
Una primera aproximación fue el libro blanco\footnote{Se conoce como libros blancos a los documentos que publican los gobiernos en determinados casos para informar a los órganos legislativos o a la opinión pública con el objetivo de ayudar a los lectores a comprender un tema, resolver o afrontar un problema (por ejemplo diseñando una política gubernamental a largo plazo), o tomar una decisión. \href{https://es.wikipedia.org/wiki/Libro_blanco}{Enlace.}} de la inteligencia artificial en 2018 \cite{whitebook2020AI}

En este trabajo propondremos una guía similar a la matriz \gls{MITRE} con buenas prácticas para la construcción de modelos más robustos y que cumplan con nuestros objetivos.

% https://ec.europa.eu/commission/presscorner/detail/en/ip_23_6473
La necesidad de desarrollar un marco de inteligencia artificial fiable para todos los miembros de la unión europea llevo a la comisión europea a la creación de nuevas normativas con un enfoque basado en el riesgo.
Por lo que exploraremos el análisis de seguridad y posibles soluciones.


\section{Objetivos primarios}
% Estudiar la seguridad en la IA
% Experimentar con modelos inseguros
% Mejorar los modelos inseguros para una mejor robustez
El objetivo principal de este trabajo es el estudio actual de la seguridad en modelos de inteligencia artificial en redes neuronales profundas, búsqueda de vectores de ataque en modelos, posibles formas de auditar los distintos modelos y costes de ataques por distintos modelos adversariales que proponemos en la sección \ref{TODO}.


\section{Objetivos secundarios}
% Desarrollar un marco matriz como mitre con buenas prácticas
% Describir los estándares de seguridad actuales
Como objetivos secundarios se ha planteado el análisis y creación de un marco de trabajo para la implementación de modelos de inteligencia artificial fiable siguiendo los estándares normativos, legislativos y éticos que propone la unión europea, con el objetivo de facilitar la implementación de modelos fiables en los distintos estados miembros.

\section{Metodología y planificación del proyecto}

Una vez definidos los objetivos del tema de investigación y desarrollo, deberemos definir el alcance para estimar el tiempo requerido y el prosupuesto para el proyecto.
Recordemos que en la investigación puede ser del tipo exploratorio, buscando nuevos campos para alcanzar nuevos logros técnicos, confirmatoria para validar los resultados obtenidos en otras investigaciones o desarrollos, tambien puede ser una combinación de los tipos menecionados previamente.
En nuestro caso se tratará de un proyecto híbrido, tanto de exploración como de confirmación.

Haremos un repaso breve de las metodologias que recomienda la bibliografía existente, recordemos que las metodologias más comunes en las áreas de las ingenierias es una metodología cuantitativa.

\subsection{Planificación y costes}

Se ha de hacer una planificación estricta de las tareas, objetivos, hitos y dependencias, para ello usaremos los diagramas Gantt\footnote{Representación gráfica de la evolución de un proyecto. \href{https://asana.com/es/resources/gantt-chart-basics}{ASANA}} con el objetivo de representar los hitos de la investigación y del proyecto.
Seguiremos una metodología \textit{Scrum} y \textit{Lean} fijando reuniones cada semana para tener un control sobre el avance de la investigación y el desarrollo de este proyecto.

Primero definiremos en la tabla la lista de tareas, fecha de inicio, duración, fecha de fin y el coste de trabajo usando la técnica de tallas de camisetas.


\section{Estructura de la memoria}

% TODO

\subsection{Metodología}

% TODO

\subsection{Presupuesto}

% TODO